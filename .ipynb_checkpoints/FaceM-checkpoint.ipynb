{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UyXDkcv3Ircx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from shutil import copy2\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qm7JO3w-JHW-"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # The %tensorflow_version magic only works in colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hadEMy5WJKgz"
      },
      "outputs": [],
      "source": [
        "import tensorflow_hub as hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pA0asp511hGi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c526b003-f3ca-4221-bd94-b29951244775"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5VLdTiAhJNDY",
        "outputId": "0af4a448-a52b-4c9e-d940-ef2dc31aa389"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "\n",
        "tf.__version__\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0Wdcug9JOwJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Increase precision of presented data for better side-by-side comparison\n",
        "pd.set_option(\"display.precision\", 8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cq_44bXxwQSv"
      },
      "outputs": [],
      "source": [
        "#!unzip -u \"/content/drive/MyDrive/OCR/Dataset2.zip\" -d \"/content/drive/MyDrive/OCR/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlDCxuIaICFV"
      },
      "outputs": [],
      "source": [
        "data_root = ('/content/drive/MyDrive/Liveness/Dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19zEBB7YIWrJ"
      },
      "outputs": [],
      "source": [
        "IMAGE_SHAPE = (224, 224) # (height, width) in no. of pixels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHY7V3BEIZJA"
      },
      "outputs": [],
      "source": [
        "TRAINING_DATA_DIR = str(data_root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sro8H-E-IaqO"
      },
      "outputs": [],
      "source": [
        "datagen_kwargs = dict(rescale=1./255, validation_split=.20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCP07qx_IdVR",
        "outputId": "5d5de883-f63e-4904-a3b7-7c88789e0b66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 484 images belonging to 2 classes.\n",
            "Found 1938 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs)\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "TRAINING_DATA_DIR,\n",
        "subset='validation',\n",
        "batch_size=16,\n",
        "shuffle=True,\n",
        "seed=123,\n",
        "class_mode='binary', # categorical or binary\n",
        "target_size=IMAGE_SHAPE\n",
        ")\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs,\n",
        "                                                                rotation_range=15, \n",
        "                                                                zoom_range=0.1,\n",
        "\t                                                              width_shift_range=0.15, \n",
        "                                                                height_shift_range=0.15, \n",
        "                                                                shear_range=0.1,\n",
        "                                                                fill_mode=\"nearest\",\n",
        "                                                                horizontal_flip=True\n",
        "                                                                )\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "TRAINING_DATA_DIR,\n",
        "subset='training',\n",
        "batch_size=16,\n",
        "shuffle=True,\n",
        "seed=123,\n",
        "class_mode='binary', # categorical or binary\n",
        "target_size=IMAGE_SHAPE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wyu947ofIixy",
        "outputId": "370723ad-46fb-49f1-eb45-d17be7b91b96"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((16, 224, 224, 3), (16,))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "\n",
        "\n",
        "for image_batch, label_batch in train_generator:\n",
        "  break\n",
        "image_batch.shape, label_batch.shape\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76-LxHNQJibp",
        "outputId": "8d4340f5-c2ad-445a-b872-bdedccc8af6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Real': 0, 'Spoof': 1}\n"
          ]
        }
      ],
      "source": [
        "print (train_generator.class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsA25JGvJ20G"
      },
      "outputs": [],
      "source": [
        "labels = '\\n'.join(sorted(train_generator.class_indices.keys()))\n",
        "\n",
        "with open('labels.txt', 'w') as f:\n",
        "  f.write(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eytoeJfQJ8Vq",
        "outputId": "c48a30a1-6a8b-4ed2-af20-1baf9ae1f69f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Real\n",
            "Spoof"
          ]
        }
      ],
      "source": [
        "!cat labels.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6iDzLxWJ-ny"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = 224"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v2_075_224/classification/5\", \n",
        "                 trainable=True)"
      ],
      "metadata": {
        "id": "V2PxIjzYLsOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import math\n"
      ],
      "metadata": {
        "id": "yNeu-AwTkA5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install h5py scikit-optimize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsRYskBalbuy",
        "outputId": "39b5b5c3-34ab-459d-9223-a7deddd6a99e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[K     |████████████████████████████████| 100 kB 3.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.1.0)\n",
            "Collecting pyaml>=16.9\n",
            "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.0.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml>=16.9->scikit-optimize) (3.13)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.1.0)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-21.10.1 scikit-optimize-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import skopt\n",
        "from skopt import gp_minimize, forest_minimize\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "from skopt.plots import plot_convergence\n",
        "from skopt.plots import plot_objective, plot_evaluations\n",
        "from skopt.plots import plot_histogram, plot_objective_2D\n",
        "from skopt.utils import use_named_args"
      ],
      "metadata": {
        "id": "vXBut8erlgrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dim_learning_rate = Real(low=1e-6, high=1e-2, prior='log-uniform',\n",
        "                         name='learning_rate')\n",
        "\n",
        "dim_num_dense_layers = Integer(low=1, high=5, name='num_dense_layers')\n",
        "\n",
        "dim_num_dense_nodes = Integer(low=5, high=512, name='num_dense_nodes')\n",
        "\n",
        "dim_activation = Categorical(categories=['relu', 'sigmoid'],\n",
        "                             name='activation')"
      ],
      "metadata": {
        "id": "5IZQ9sbqkNkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dimensions = [dim_learning_rate,\n",
        "              dim_num_dense_layers,\n",
        "              dim_num_dense_nodes,\n",
        "              dim_activation]"
      ],
      "metadata": {
        "id": "OPpal6bTkXur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "default_parameters = [1e-5, 1, 16, 'relu']"
      ],
      "metadata": {
        "id": "dmP43tqfkbdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_best_model = '/content/drive/MyDrive/Liveness/Model/best_model.h5'"
      ],
      "metadata": {
        "id": "jNRR5d5QsX_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_accuracy = 0.0"
      ],
      "metadata": {
        "id": "ZtASpNv6sZ4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision = tf.keras.metrics.Precision()\n",
        "recall = tf.keras.metrics.Recall()"
      ],
      "metadata": {
        "id": "9ZEOLGAM32GP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch = np.ceil(train_generator.samples/train_generator.batch_size)\n",
        "val_steps_per_epoch = np.ceil(valid_generator.samples/valid_generator.batch_size)"
      ],
      "metadata": {
        "id": "JymlisTBEcnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_dir_name(learning_rate, num_dense_layers,\n",
        "                 num_dense_nodes, activation):\n",
        "\n",
        "    # The dir-name for the TensorBoard log-dir.\n",
        "    s = \"./19_logs/lr_{0:.0e}_layers_{1}_nodes_{2}_{3}/\"\n",
        "\n",
        "    # Insert all the hyper-parameters in the dir-name.\n",
        "    log_dir = s.format(learning_rate,\n",
        "                       num_dense_layers,\n",
        "                       num_dense_nodes,\n",
        "                       activation)\n",
        "\n",
        "    return log_dir"
      ],
      "metadata": {
        "id": "kSkCWjzVvhL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import InputLayer, Input\n",
        "from tensorflow.keras.layers import Reshape, MaxPooling2D\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "WEw-1Mw7vGk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(learning_rate, num_dense_layers,\n",
        "                 num_dense_nodes, activation):\n",
        "    \"\"\"\n",
        "    Hyper-parameters:\n",
        "    learning_rate:     Learning-rate for the optimizer.\n",
        "    num_dense_layers:  Number of dense layers.\n",
        "    num_dense_nodes:   Number of nodes in each dense layer.\n",
        "    activation:        Activation function for all layers.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Start construction of a Keras Sequential model.\n",
        "    model = Sequential()\n",
        "\n",
        "    # Add an input layer which is similar to a feed_dict in TensorFlow.\n",
        "    # Note that the input-shape must be a tuple containing the image-size.\n",
        "    model.add(base_model)\n",
        "\n",
        "    # Add fully-connected / dense layers.\n",
        "    # The number of layers is a hyper-parameter we want to optimize.\n",
        "    for i in range(num_dense_layers):\n",
        "        # Name of the layer. This is not really necessary\n",
        "        # because Keras should give them unique names.\n",
        "        name = 'layer_dense_{0}'.format(i+1)\n",
        "\n",
        "        # Add the dense / fully-connected layer to the model.\n",
        "        # This has two hyper-parameters we want to optimize:\n",
        "        # The number of nodes and the activation function.\n",
        "        model.add(Dense(num_dense_nodes,\n",
        "                        activation=activation,\n",
        "                        name=name))\n",
        "\n",
        "    # Last fully-connected / dense layer with softmax-activation\n",
        "    # for use in classification.\n",
        "    \n",
        "    model.add(Dense(train_generator.num_classes-1, activation='sigmoid'))\n",
        "    \n",
        "    # Use the Adam method for training the network.\n",
        "    # We want to find the best learning-rate for the Adam method.\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    \n",
        "    # In Keras we need to compile the model so it can be trained.\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy', precision, recall])\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "9Ds0xOl8tbWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@use_named_args(dimensions=dimensions)\n",
        "\n",
        "def fitness(learning_rate, num_dense_layers,\n",
        "            num_dense_nodes, activation):\n",
        "    \"\"\"\n",
        "    Hyper-parameters:\n",
        "    learning_rate:     Learning-rate for the optimizer.\n",
        "    num_dense_layers:  Number of dense layers.\n",
        "    num_dense_nodes:   Number of nodes in each dense layer.\n",
        "    activation:        Activation function for all layers.\n",
        "    \"\"\"\n",
        "\n",
        "    # Print the hyper-parameters.\n",
        "    print('learning rate: {0:.1e}'.format(learning_rate))\n",
        "    print('num_dense_layers:', num_dense_layers)\n",
        "    print('num_dense_nodes:', num_dense_nodes)\n",
        "    print('activation:', activation)\n",
        "    print()\n",
        "    \n",
        "    # Create the neural network with these hyper-parameters.\n",
        "    model = create_model(learning_rate=learning_rate,\n",
        "                         num_dense_layers=num_dense_layers,\n",
        "                         num_dense_nodes=num_dense_nodes,\n",
        "                         activation=activation)\n",
        "\n",
        "    # Dir-name for the TensorBoard log-files.\n",
        "    log_dir = log_dir_name(learning_rate, num_dense_layers,\n",
        "                           num_dense_nodes, activation)\n",
        "    \n",
        "    # Create a callback-function for Keras which will be\n",
        "    # run after each epoch has ended during training.\n",
        "    # This saves the log-files for TensorBoard.\n",
        "    # Note that there are complications when histogram_freq=1.\n",
        "    # It might give strange errors and it also does not properly\n",
        "    # support Keras data-generators for the validation-set.\n",
        "    callback_log = TensorBoard(\n",
        "        log_dir=log_dir,\n",
        "        histogram_freq=0,\n",
        "        write_graph=True,\n",
        "        write_grads=False,\n",
        "        write_images=False)\n",
        "   \n",
        "    # Use Keras to train the model.\n",
        "    history = model.fit(train_generator,\n",
        "                        epochs=19,\n",
        "                        validation_data=valid_generator,\n",
        "                        steps_per_epoch=steps_per_epoch,\n",
        "                        validation_steps=val_steps_per_epoch,\n",
        "                        callbacks=[callback_log])\n",
        "    \n",
        "\n",
        "\n",
        "    # Get the classification accuracy on the validation-set\n",
        "    # after the last training-epoch.\n",
        "    accuracy = history.history['val_accuracy'][-1]\n",
        "\n",
        "    # Print the classification accuracy.\n",
        "    print()\n",
        "    print(\"Accuracy: {0:.2%}\".format(accuracy))\n",
        "    print()\n",
        "\n",
        "    # Save the model if it improves on the best-found performance.\n",
        "    # We use the global keyword so we update the variable outside\n",
        "    # of this function.\n",
        "    global best_accuracy\n",
        "\n",
        "    # If the classification accuracy of the saved model is improved ...\n",
        "    if accuracy > best_accuracy:\n",
        "        # Save the new model to harddisk.\n",
        "        model.save(path_best_model)\n",
        "        \n",
        "        # Update the classification accuracy.\n",
        "        best_accuracy = accuracy\n",
        "\n",
        "    # Delete the Keras model with these hyper-parameters from memory.\n",
        "    del model\n",
        "    \n",
        "    # Clear the Keras session, otherwise it will keep adding new\n",
        "    # models to the same TensorFlow graph each time we create\n",
        "    # a model with a different set of hyper-parameters.\n",
        "    K.clear_session()\n",
        "    \n",
        "    # NOTE: Scikit-optimize does minimization so it tries to\n",
        "    # find a set of hyper-parameters with the LOWEST fitness-value.\n",
        "    # Because we are interested in the HIGHEST classification\n",
        "    # accuracy, we need to negate this number so it can be minimized.\n",
        "    return -accuracy"
      ],
      "metadata": {
        "id": "DEnzyO49sRpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fitness(x=default_parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pop1Kye3s_V_",
        "outputId": "66da8cbe-b642-496a-beba-046012fd61d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learning rate: 1.0e-05\n",
            "num_dense_layers: 1\n",
            "num_dense_nodes: 16\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/19\n",
            "122/122 [==============================] - 268s 2s/step - loss: 0.7552 - accuracy: 0.6465 - precision: 0.6488 - recall: 0.6374 - val_loss: 0.7006 - val_accuracy: 0.6901 - val_precision: 0.8333 - val_recall: 0.4752\n",
            "Epoch 2/19\n",
            "122/122 [==============================] - 37s 304ms/step - loss: 0.5260 - accuracy: 0.8086 - precision: 0.8113 - recall: 0.8037 - val_loss: 0.4382 - val_accuracy: 0.8471 - val_precision: 0.8529 - val_recall: 0.8388\n",
            "Epoch 3/19\n",
            "122/122 [==============================] - 37s 302ms/step - loss: 0.4314 - accuracy: 0.8658 - precision: 0.8649 - recall: 0.8667 - val_loss: 0.3737 - val_accuracy: 0.8905 - val_precision: 0.8677 - val_recall: 0.9215\n",
            "Epoch 4/19\n",
            "122/122 [==============================] - 37s 303ms/step - loss: 0.3621 - accuracy: 0.8983 - precision: 0.8962 - recall: 0.9008 - val_loss: 0.3324 - val_accuracy: 0.9070 - val_precision: 0.8556 - val_recall: 0.9793\n",
            "Epoch 5/19\n",
            "122/122 [==============================] - 38s 312ms/step - loss: 0.3374 - accuracy: 0.9045 - precision: 0.8943 - recall: 0.9174 - val_loss: 0.3066 - val_accuracy: 0.9194 - val_precision: 0.8664 - val_recall: 0.9917\n",
            "Epoch 6/19\n",
            "122/122 [==============================] - 38s 308ms/step - loss: 0.2770 - accuracy: 0.9365 - precision: 0.9263 - recall: 0.9483 - val_loss: 0.2562 - val_accuracy: 0.9607 - val_precision: 0.9407 - val_recall: 0.9835\n",
            "Epoch 7/19\n",
            "122/122 [==============================] - 37s 301ms/step - loss: 0.2868 - accuracy: 0.9345 - precision: 0.9278 - recall: 0.9421 - val_loss: 0.2343 - val_accuracy: 0.9628 - val_precision: 0.9409 - val_recall: 0.9876\n",
            "Epoch 8/19\n",
            "122/122 [==============================] - 37s 302ms/step - loss: 0.2504 - accuracy: 0.9463 - precision: 0.9500 - recall: 0.9421 - val_loss: 0.2328 - val_accuracy: 0.9607 - val_precision: 0.9339 - val_recall: 0.9917\n",
            "Epoch 9/19\n",
            "122/122 [==============================] - 37s 302ms/step - loss: 0.2512 - accuracy: 0.9463 - precision: 0.9426 - recall: 0.9504 - val_loss: 0.2330 - val_accuracy: 0.9628 - val_precision: 0.9341 - val_recall: 0.9959\n",
            "Epoch 10/19\n",
            "122/122 [==============================] - 39s 322ms/step - loss: 0.2293 - accuracy: 0.9567 - precision: 0.9557 - recall: 0.9576 - val_loss: 0.2137 - val_accuracy: 0.9690 - val_precision: 0.9416 - val_recall: 1.0000\n",
            "Epoch 11/19\n",
            "122/122 [==============================] - 37s 302ms/step - loss: 0.2426 - accuracy: 0.9489 - precision: 0.9512 - recall: 0.9463 - val_loss: 0.1904 - val_accuracy: 0.9793 - val_precision: 0.9603 - val_recall: 1.0000\n",
            "Epoch 12/19\n",
            "122/122 [==============================] - 37s 299ms/step - loss: 0.2189 - accuracy: 0.9613 - precision: 0.9561 - recall: 0.9669 - val_loss: 0.1825 - val_accuracy: 0.9876 - val_precision: 0.9758 - val_recall: 1.0000\n",
            "Epoch 13/19\n",
            "122/122 [==============================] - 39s 316ms/step - loss: 0.2038 - accuracy: 0.9665 - precision: 0.9659 - recall: 0.9669 - val_loss: 0.1829 - val_accuracy: 0.9855 - val_precision: 0.9719 - val_recall: 1.0000\n",
            "Epoch 14/19\n",
            "122/122 [==============================] - 38s 309ms/step - loss: 0.1796 - accuracy: 0.9778 - precision: 0.9773 - recall: 0.9783 - val_loss: 0.1836 - val_accuracy: 0.9793 - val_precision: 0.9603 - val_recall: 1.0000\n",
            "Epoch 15/19\n",
            "122/122 [==============================] - 36s 297ms/step - loss: 0.1939 - accuracy: 0.9680 - precision: 0.9680 - recall: 0.9680 - val_loss: 0.1757 - val_accuracy: 0.9876 - val_precision: 0.9758 - val_recall: 1.0000\n",
            "Epoch 16/19\n",
            "122/122 [==============================] - 36s 293ms/step - loss: 0.1896 - accuracy: 0.9742 - precision: 0.9732 - recall: 0.9752 - val_loss: 0.1817 - val_accuracy: 0.9773 - val_precision: 0.9565 - val_recall: 1.0000\n",
            "Epoch 17/19\n",
            "122/122 [==============================] - 36s 292ms/step - loss: 0.1861 - accuracy: 0.9773 - precision: 0.9773 - recall: 0.9773 - val_loss: 0.1594 - val_accuracy: 0.9917 - val_precision: 0.9837 - val_recall: 1.0000\n",
            "Epoch 18/19\n",
            "122/122 [==============================] - 36s 292ms/step - loss: 0.1826 - accuracy: 0.9778 - precision: 0.9783 - recall: 0.9773 - val_loss: 0.1623 - val_accuracy: 0.9897 - val_precision: 0.9798 - val_recall: 1.0000\n",
            "Epoch 19/19\n",
            "122/122 [==============================] - 36s 294ms/step - loss: 0.1694 - accuracy: 0.9809 - precision: 0.9774 - recall: 0.9845 - val_loss: 0.1538 - val_accuracy: 0.9917 - val_precision: 0.9837 - val_recall: 1.0000\n",
            "\n",
            "Accuracy: 99.17%\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.9917355179786682"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "search_result = gp_minimize(func=fitness,\n",
        "                            dimensions=dimensions,\n",
        "                            acq_func='EI', # Expected Improvement.\n",
        "                            n_calls=50,\n",
        "                            x0=default_parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mmcQcv3DwDKj",
        "outputId": "7075d12a-108f-41a1-b8e5-bd570874e476"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learning rate: 1.0e-05\n",
            "num_dense_layers: 1\n",
            "num_dense_nodes: 16\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/19\n",
            "122/122 [==============================] - 60s 452ms/step - loss: 0.5372 - accuracy: 0.7910 - precision: 0.8102 - recall: 0.8645 - val_loss: 0.2703 - val_accuracy: 0.9401 - val_precision: 0.8989 - val_recall: 0.9917\n",
            "Epoch 2/19\n",
            "122/122 [==============================] - 40s 326ms/step - loss: 0.2783 - accuracy: 0.9412 - precision: 0.9420 - recall: 0.9401 - val_loss: 0.1928 - val_accuracy: 0.9835 - val_precision: 0.9718 - val_recall: 0.9959\n",
            "Epoch 3/19\n",
            "122/122 [==============================] - 40s 331ms/step - loss: 0.2326 - accuracy: 0.9556 - precision: 0.9509 - recall: 0.9607 - val_loss: 0.1663 - val_accuracy: 0.9876 - val_precision: 0.9797 - val_recall: 0.9959\n",
            "Epoch 4/19\n",
            "122/122 [==============================] - 39s 319ms/step - loss: 0.1906 - accuracy: 0.9727 - precision: 0.9683 - recall: 0.9773 - val_loss: 0.1595 - val_accuracy: 0.9855 - val_precision: 0.9757 - val_recall: 0.9959\n",
            "Epoch 5/19\n",
            "122/122 [==============================] - 37s 303ms/step - loss: 0.1825 - accuracy: 0.9778 - precision: 0.9793 - recall: 0.9762 - val_loss: 0.1441 - val_accuracy: 0.9938 - val_precision: 0.9918 - val_recall: 0.9959\n",
            "Epoch 6/19\n",
            "122/122 [==============================] - 37s 300ms/step - loss: 0.1832 - accuracy: 0.9732 - precision: 0.9645 - recall: 0.9824 - val_loss: 0.1439 - val_accuracy: 0.9938 - val_precision: 0.9878 - val_recall: 1.0000\n",
            "Epoch 7/19\n",
            "122/122 [==============================] - 36s 298ms/step - loss: 0.1829 - accuracy: 0.9737 - precision: 0.9741 - recall: 0.9731 - val_loss: 0.1455 - val_accuracy: 0.9897 - val_precision: 0.9798 - val_recall: 1.0000\n",
            "Epoch 8/19\n",
            "122/122 [==============================] - 36s 298ms/step - loss: 0.1709 - accuracy: 0.9773 - precision: 0.9783 - recall: 0.9762 - val_loss: 0.1328 - val_accuracy: 0.9938 - val_precision: 0.9918 - val_recall: 0.9959\n",
            "Epoch 9/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.1835 - accuracy: 0.9732 - precision: 0.9771 - recall: 0.9690 - val_loss: 0.1288 - val_accuracy: 0.9938 - val_precision: 0.9918 - val_recall: 0.9959\n",
            "Epoch 10/19\n",
            "122/122 [==============================] - 36s 298ms/step - loss: 0.1692 - accuracy: 0.9794 - precision: 0.9764 - recall: 0.9824 - val_loss: 0.1308 - val_accuracy: 0.9959 - val_precision: 0.9918 - val_recall: 1.0000\n",
            "Epoch 11/19\n",
            "122/122 [==============================] - 37s 300ms/step - loss: 0.1516 - accuracy: 0.9830 - precision: 0.9785 - recall: 0.9876 - val_loss: 0.1339 - val_accuracy: 0.9938 - val_precision: 0.9878 - val_recall: 1.0000\n",
            "Epoch 12/19\n",
            "122/122 [==============================] - 38s 311ms/step - loss: 0.1435 - accuracy: 0.9902 - precision: 0.9907 - recall: 0.9897 - val_loss: 0.1306 - val_accuracy: 0.9959 - val_precision: 0.9918 - val_recall: 1.0000\n",
            "Epoch 13/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.1582 - accuracy: 0.9850 - precision: 0.9825 - recall: 0.9876 - val_loss: 0.1281 - val_accuracy: 0.9959 - val_precision: 0.9918 - val_recall: 1.0000\n",
            "Epoch 14/19\n",
            "122/122 [==============================] - 36s 298ms/step - loss: 0.1574 - accuracy: 0.9840 - precision: 0.9825 - recall: 0.9855 - val_loss: 0.1278 - val_accuracy: 0.9959 - val_precision: 0.9918 - val_recall: 1.0000\n",
            "Epoch 15/19\n",
            "122/122 [==============================] - 36s 298ms/step - loss: 0.1469 - accuracy: 0.9871 - precision: 0.9866 - recall: 0.9876 - val_loss: 0.1215 - val_accuracy: 0.9959 - val_precision: 0.9918 - val_recall: 1.0000\n",
            "Epoch 16/19\n",
            "122/122 [==============================] - 36s 297ms/step - loss: 0.1540 - accuracy: 0.9861 - precision: 0.9876 - recall: 0.9845 - val_loss: 0.1256 - val_accuracy: 0.9959 - val_precision: 0.9918 - val_recall: 1.0000\n",
            "Epoch 17/19\n",
            "122/122 [==============================] - 37s 307ms/step - loss: 0.1549 - accuracy: 0.9830 - precision: 0.9855 - recall: 0.9804 - val_loss: 0.1250 - val_accuracy: 0.9959 - val_precision: 0.9918 - val_recall: 1.0000\n",
            "Epoch 18/19\n",
            "122/122 [==============================] - 38s 307ms/step - loss: 0.1492 - accuracy: 0.9845 - precision: 0.9796 - recall: 0.9897 - val_loss: 0.1286 - val_accuracy: 0.9959 - val_precision: 0.9918 - val_recall: 1.0000\n",
            "Epoch 19/19\n",
            "122/122 [==============================] - 37s 303ms/step - loss: 0.1410 - accuracy: 0.9897 - precision: 0.9927 - recall: 0.9866 - val_loss: 0.1260 - val_accuracy: 0.9959 - val_precision: 0.9918 - val_recall: 1.0000\n",
            "\n",
            "Accuracy: 99.59%\n",
            "\n",
            "learning rate: 1.1e-04\n",
            "num_dense_layers: 5\n",
            "num_dense_nodes: 496\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/19\n",
            "122/122 [==============================] - 43s 315ms/step - loss: 0.2124 - accuracy: 0.9675 - precision: 0.9704 - recall: 0.9760 - val_loss: 0.2290 - val_accuracy: 0.9587 - val_precision: 1.0000 - val_recall: 0.9174\n",
            "Epoch 2/19\n",
            "122/122 [==============================] - 36s 297ms/step - loss: 0.1911 - accuracy: 0.9727 - precision: 0.9731 - recall: 0.9721 - val_loss: 0.1501 - val_accuracy: 0.9855 - val_precision: 0.9757 - val_recall: 0.9959\n",
            "Epoch 3/19\n",
            "122/122 [==============================] - 36s 297ms/step - loss: 0.1762 - accuracy: 0.9804 - precision: 0.9774 - recall: 0.9835 - val_loss: 0.1636 - val_accuracy: 0.9752 - val_precision: 0.9528 - val_recall: 1.0000\n",
            "Epoch 4/19\n",
            "122/122 [==============================] - 36s 297ms/step - loss: 0.1642 - accuracy: 0.9845 - precision: 0.9855 - recall: 0.9835 - val_loss: 0.1348 - val_accuracy: 0.9917 - val_precision: 0.9958 - val_recall: 0.9876\n",
            "Epoch 5/19\n",
            "122/122 [==============================] - 36s 295ms/step - loss: 0.1617 - accuracy: 0.9804 - precision: 0.9804 - recall: 0.9804 - val_loss: 0.2184 - val_accuracy: 0.9587 - val_precision: 0.9237 - val_recall: 1.0000\n",
            "Epoch 6/19\n",
            "122/122 [==============================] - 36s 298ms/step - loss: 0.1419 - accuracy: 0.9876 - precision: 0.9896 - recall: 0.9855 - val_loss: 0.1346 - val_accuracy: 0.9959 - val_precision: 0.9918 - val_recall: 1.0000\n",
            "Epoch 7/19\n",
            "122/122 [==============================] - 36s 298ms/step - loss: 0.1638 - accuracy: 0.9861 - precision: 0.9836 - recall: 0.9886 - val_loss: 0.1368 - val_accuracy: 0.9938 - val_precision: 0.9918 - val_recall: 0.9959\n",
            "Epoch 8/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.1629 - accuracy: 0.9856 - precision: 0.9855 - recall: 0.9855 - val_loss: 0.1443 - val_accuracy: 0.9897 - val_precision: 1.0000 - val_recall: 0.9793\n",
            "Epoch 9/19\n",
            "122/122 [==============================] - 37s 301ms/step - loss: 0.1372 - accuracy: 0.9897 - precision: 0.9897 - recall: 0.9897 - val_loss: 0.1301 - val_accuracy: 0.9959 - val_precision: 0.9918 - val_recall: 1.0000\n",
            "Epoch 10/19\n",
            "122/122 [==============================] - 37s 301ms/step - loss: 0.1336 - accuracy: 0.9923 - precision: 0.9917 - recall: 0.9928 - val_loss: 0.1333 - val_accuracy: 0.9897 - val_precision: 0.9837 - val_recall: 0.9959\n",
            "Epoch 11/19\n",
            "122/122 [==============================] - 37s 298ms/step - loss: 0.1226 - accuracy: 0.9959 - precision: 0.9948 - recall: 0.9969 - val_loss: 0.1406 - val_accuracy: 0.9917 - val_precision: 0.9837 - val_recall: 1.0000\n",
            "Epoch 12/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.1306 - accuracy: 0.9923 - precision: 0.9928 - recall: 0.9917 - val_loss: 0.1318 - val_accuracy: 0.9938 - val_precision: 0.9878 - val_recall: 1.0000\n",
            "Epoch 13/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.1833 - accuracy: 0.9783 - precision: 0.9803 - recall: 0.9762 - val_loss: 0.1527 - val_accuracy: 0.9855 - val_precision: 0.9719 - val_recall: 1.0000\n",
            "Epoch 14/19\n",
            "122/122 [==============================] - 36s 293ms/step - loss: 0.1424 - accuracy: 0.9897 - precision: 0.9897 - recall: 0.9897 - val_loss: 0.1432 - val_accuracy: 0.9938 - val_precision: 0.9878 - val_recall: 1.0000\n",
            "Epoch 15/19\n",
            "122/122 [==============================] - 36s 295ms/step - loss: 0.1325 - accuracy: 0.9928 - precision: 0.9928 - recall: 0.9928 - val_loss: 0.1278 - val_accuracy: 0.9979 - val_precision: 0.9959 - val_recall: 1.0000\n",
            "Epoch 16/19\n",
            "122/122 [==============================] - 36s 294ms/step - loss: 0.1586 - accuracy: 0.9907 - precision: 0.9887 - recall: 0.9928 - val_loss: 0.2665 - val_accuracy: 0.9339 - val_precision: 0.9861 - val_recall: 0.8802\n",
            "Epoch 17/19\n",
            "122/122 [==============================] - 36s 293ms/step - loss: 0.1503 - accuracy: 0.9866 - precision: 0.9886 - recall: 0.9845 - val_loss: 0.1393 - val_accuracy: 0.9979 - val_precision: 0.9959 - val_recall: 1.0000\n",
            "Epoch 18/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.1248 - accuracy: 0.9959 - precision: 0.9959 - recall: 0.9959 - val_loss: 0.1179 - val_accuracy: 0.9938 - val_precision: 0.9878 - val_recall: 1.0000\n",
            "Epoch 19/19\n",
            "122/122 [==============================] - 38s 312ms/step - loss: 0.1270 - accuracy: 0.9959 - precision: 0.9979 - recall: 0.9938 - val_loss: 0.1144 - val_accuracy: 0.9979 - val_precision: 0.9959 - val_recall: 1.0000\n",
            "\n",
            "Accuracy: 99.79%\n",
            "\n",
            "learning rate: 2.2e-03\n",
            "num_dense_layers: 3\n",
            "num_dense_nodes: 495\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/19\n",
            "122/122 [==============================] - 41s 301ms/step - loss: 0.8483 - accuracy: 0.8065 - precision: 0.8159 - recall: 0.8901 - val_loss: 2.4053 - val_accuracy: 0.8058 - val_precision: 0.9805 - val_recall: 0.6240\n",
            "Epoch 2/19\n",
            "122/122 [==============================] - 36s 294ms/step - loss: 0.3321 - accuracy: 0.9205 - precision: 0.9205 - recall: 0.9205 - val_loss: 0.8383 - val_accuracy: 0.8884 - val_precision: 0.8264 - val_recall: 0.9835\n",
            "Epoch 3/19\n",
            "122/122 [==============================] - 36s 294ms/step - loss: 0.2808 - accuracy: 0.9340 - precision: 0.9303 - recall: 0.9380 - val_loss: 3.5307 - val_accuracy: 0.7479 - val_precision: 0.6648 - val_recall: 1.0000\n",
            "Epoch 4/19\n",
            "122/122 [==============================] - 36s 293ms/step - loss: 0.3417 - accuracy: 0.9293 - precision: 0.9482 - recall: 0.9081 - val_loss: 1.6275 - val_accuracy: 0.8822 - val_precision: 0.8136 - val_recall: 0.9917\n",
            "Epoch 5/19\n",
            "122/122 [==============================] - 36s 294ms/step - loss: 0.5422 - accuracy: 0.8720 - precision: 0.8814 - recall: 0.8595 - val_loss: 1.9733 - val_accuracy: 0.7128 - val_precision: 0.9725 - val_recall: 0.4380\n",
            "Epoch 6/19\n",
            "122/122 [==============================] - 36s 293ms/step - loss: 0.4775 - accuracy: 0.8622 - precision: 0.8856 - recall: 0.8316 - val_loss: 1.6830 - val_accuracy: 0.7831 - val_precision: 0.9790 - val_recall: 0.5785\n",
            "Epoch 7/19\n",
            "122/122 [==============================] - 36s 298ms/step - loss: 0.3510 - accuracy: 0.9133 - precision: 0.9246 - recall: 0.8998 - val_loss: 0.2156 - val_accuracy: 0.9711 - val_precision: 0.9597 - val_recall: 0.9835\n",
            "Epoch 8/19\n",
            "122/122 [==============================] - 36s 293ms/step - loss: 0.2439 - accuracy: 0.9499 - precision: 0.9579 - recall: 0.9411 - val_loss: 2.0092 - val_accuracy: 0.7459 - val_precision: 0.6630 - val_recall: 1.0000\n",
            "Epoch 9/19\n",
            "122/122 [==============================] - 38s 307ms/step - loss: 0.1950 - accuracy: 0.9659 - precision: 0.9640 - recall: 0.9680 - val_loss: 0.2324 - val_accuracy: 0.9628 - val_precision: 0.9375 - val_recall: 0.9917\n",
            "Epoch 10/19\n",
            "122/122 [==============================] - 36s 297ms/step - loss: 0.2681 - accuracy: 0.9443 - precision: 0.9300 - recall: 0.9607 - val_loss: 0.2291 - val_accuracy: 0.9628 - val_precision: 0.9912 - val_recall: 0.9339\n",
            "Epoch 11/19\n",
            "122/122 [==============================] - 36s 295ms/step - loss: 0.5514 - accuracy: 0.8277 - precision: 0.8351 - recall: 0.8161 - val_loss: 1.1316 - val_accuracy: 0.5227 - val_precision: 1.0000 - val_recall: 0.0455\n",
            "Epoch 12/19\n",
            "122/122 [==============================] - 36s 295ms/step - loss: 0.4086 - accuracy: 0.8767 - precision: 0.8857 - recall: 0.8647 - val_loss: 0.2338 - val_accuracy: 0.9483 - val_precision: 0.9222 - val_recall: 0.9793\n",
            "Epoch 13/19\n",
            "122/122 [==============================] - 36s 294ms/step - loss: 0.3992 - accuracy: 0.8973 - precision: 0.8857 - recall: 0.9122 - val_loss: 0.8495 - val_accuracy: 0.8512 - val_precision: 0.7911 - val_recall: 0.9545\n",
            "Epoch 14/19\n",
            "122/122 [==============================] - 36s 293ms/step - loss: 0.2609 - accuracy: 0.9360 - precision: 0.9245 - recall: 0.9494 - val_loss: 0.2569 - val_accuracy: 0.9545 - val_precision: 0.9911 - val_recall: 0.9174\n",
            "Epoch 15/19\n",
            "122/122 [==============================] - 37s 299ms/step - loss: 0.4077 - accuracy: 0.8891 - precision: 0.9106 - recall: 0.8626 - val_loss: 1.9724 - val_accuracy: 0.6405 - val_precision: 0.5817 - val_recall: 1.0000\n",
            "Epoch 16/19\n",
            "122/122 [==============================] - 36s 297ms/step - loss: 0.2681 - accuracy: 0.9448 - precision: 0.9517 - recall: 0.9370 - val_loss: 0.1654 - val_accuracy: 0.9711 - val_precision: 0.9524 - val_recall: 0.9917\n",
            "Epoch 17/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.2534 - accuracy: 0.9479 - precision: 0.9410 - recall: 0.9556 - val_loss: 0.2028 - val_accuracy: 0.9731 - val_precision: 0.9751 - val_recall: 0.9711\n",
            "Epoch 18/19\n",
            "122/122 [==============================] - 38s 307ms/step - loss: 0.1967 - accuracy: 0.9623 - precision: 0.9618 - recall: 0.9628 - val_loss: 0.1258 - val_accuracy: 0.9897 - val_precision: 1.0000 - val_recall: 0.9793\n",
            "Epoch 19/19\n",
            "122/122 [==============================] - 36s 298ms/step - loss: 0.3496 - accuracy: 0.9045 - precision: 0.9134 - recall: 0.8936 - val_loss: 0.7968 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "\n",
            "Accuracy: 50.00%\n",
            "\n",
            "learning rate: 1.1e-03\n",
            "num_dense_layers: 2\n",
            "num_dense_nodes: 227\n",
            "activation: sigmoid\n",
            "\n",
            "Epoch 1/19\n",
            "122/122 [==============================] - 43s 309ms/step - loss: 0.3299 - accuracy: 0.8973 - precision: 0.9069 - recall: 0.7083 - val_loss: 0.4027 - val_accuracy: 0.9070 - val_precision: 1.0000 - val_recall: 0.8140\n",
            "Epoch 2/19\n",
            "122/122 [==============================] - 37s 301ms/step - loss: 0.2260 - accuracy: 0.9469 - precision: 0.9473 - recall: 0.9463 - val_loss: 0.2532 - val_accuracy: 0.9360 - val_precision: 0.8864 - val_recall: 1.0000\n",
            "Epoch 3/19\n",
            "122/122 [==============================] - 37s 300ms/step - loss: 0.1950 - accuracy: 0.9515 - precision: 0.9379 - recall: 0.9669 - val_loss: 0.3035 - val_accuracy: 0.9401 - val_precision: 1.0000 - val_recall: 0.8802\n",
            "Epoch 4/19\n",
            "122/122 [==============================] - 36s 298ms/step - loss: 0.5072 - accuracy: 0.7957 - precision: 0.8095 - recall: 0.7727 - val_loss: 0.7427 - val_accuracy: 0.7169 - val_precision: 0.6780 - val_recall: 0.8264\n",
            "Epoch 5/19\n",
            "122/122 [==============================] - 37s 299ms/step - loss: 0.4095 - accuracy: 0.8746 - precision: 0.8323 - recall: 0.9380 - val_loss: 0.7401 - val_accuracy: 0.8161 - val_precision: 0.9935 - val_recall: 0.6364\n",
            "Epoch 6/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.2849 - accuracy: 0.9334 - precision: 0.9216 - recall: 0.9473 - val_loss: 0.2870 - val_accuracy: 0.9442 - val_precision: 0.8996 - val_recall: 1.0000\n",
            "Epoch 7/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.2408 - accuracy: 0.9438 - precision: 0.9414 - recall: 0.9463 - val_loss: 0.2452 - val_accuracy: 0.9566 - val_precision: 0.9510 - val_recall: 0.9628\n",
            "Epoch 8/19\n",
            "122/122 [==============================] - 37s 307ms/step - loss: 0.2042 - accuracy: 0.9618 - precision: 0.9571 - recall: 0.9669 - val_loss: 0.5494 - val_accuracy: 0.8802 - val_precision: 0.8067 - val_recall: 1.0000\n",
            "Epoch 9/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.5240 - accuracy: 0.8271 - precision: 0.8273 - recall: 0.8264 - val_loss: 0.5529 - val_accuracy: 0.8843 - val_precision: 1.0000 - val_recall: 0.7686\n",
            "Epoch 10/19\n",
            "122/122 [==============================] - 36s 295ms/step - loss: 0.3025 - accuracy: 0.9236 - precision: 0.9125 - recall: 0.9370 - val_loss: 0.3261 - val_accuracy: 0.9318 - val_precision: 0.9729 - val_recall: 0.8884\n",
            "Epoch 11/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.2409 - accuracy: 0.9458 - precision: 0.9381 - recall: 0.9545 - val_loss: 0.1713 - val_accuracy: 0.9752 - val_precision: 0.9563 - val_recall: 0.9959\n",
            "Epoch 12/19\n",
            "122/122 [==============================] - 36s 298ms/step - loss: 0.1806 - accuracy: 0.9685 - precision: 0.9709 - recall: 0.9659 - val_loss: 0.1489 - val_accuracy: 0.9793 - val_precision: 0.9754 - val_recall: 0.9835\n",
            "Epoch 13/19\n",
            "122/122 [==============================] - 37s 301ms/step - loss: 0.1627 - accuracy: 0.9685 - precision: 0.9670 - recall: 0.9700 - val_loss: 0.2675 - val_accuracy: 0.9360 - val_precision: 0.8893 - val_recall: 0.9959\n",
            "Epoch 14/19\n",
            "122/122 [==============================] - 36s 295ms/step - loss: 0.1589 - accuracy: 0.9690 - precision: 0.9652 - recall: 0.9731 - val_loss: 0.1601 - val_accuracy: 0.9628 - val_precision: 0.9828 - val_recall: 0.9421\n",
            "Epoch 15/19\n",
            "122/122 [==============================] - 36s 292ms/step - loss: 0.1746 - accuracy: 0.9675 - precision: 0.9651 - recall: 0.9700 - val_loss: 0.1609 - val_accuracy: 0.9773 - val_precision: 0.9676 - val_recall: 0.9876\n",
            "Epoch 16/19\n",
            "122/122 [==============================] - 36s 293ms/step - loss: 0.2036 - accuracy: 0.9618 - precision: 0.9656 - recall: 0.9576 - val_loss: 0.1962 - val_accuracy: 0.9669 - val_precision: 1.0000 - val_recall: 0.9339\n",
            "Epoch 17/19\n",
            "122/122 [==============================] - 37s 303ms/step - loss: 0.1603 - accuracy: 0.9732 - precision: 0.9741 - recall: 0.9721 - val_loss: 0.1267 - val_accuracy: 0.9876 - val_precision: 0.9917 - val_recall: 0.9835\n",
            "Epoch 18/19\n",
            "122/122 [==============================] - 36s 293ms/step - loss: 0.1430 - accuracy: 0.9778 - precision: 0.9823 - recall: 0.9731 - val_loss: 0.1986 - val_accuracy: 0.9587 - val_precision: 1.0000 - val_recall: 0.9174\n",
            "Epoch 19/19\n",
            "122/122 [==============================] - 36s 291ms/step - loss: 0.2440 - accuracy: 0.9283 - precision: 0.9377 - recall: 0.9174 - val_loss: 1.6659 - val_accuracy: 0.6322 - val_precision: 0.5762 - val_recall: 1.0000\n",
            "\n",
            "Accuracy: 63.22%\n",
            "\n",
            "learning rate: 2.0e-03\n",
            "num_dense_layers: 3\n",
            "num_dense_nodes: 320\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/19\n",
            "122/122 [==============================] - 41s 301ms/step - loss: 0.8218 - accuracy: 0.8261 - precision: 0.7405 - recall: 0.8843 - val_loss: 0.6596 - val_accuracy: 0.8822 - val_precision: 0.8201 - val_recall: 0.9793\n",
            "Epoch 2/19\n",
            "122/122 [==============================] - 36s 297ms/step - loss: 0.2809 - accuracy: 0.9340 - precision: 0.9357 - recall: 0.9318 - val_loss: 0.2647 - val_accuracy: 0.9318 - val_precision: 0.9604 - val_recall: 0.9008\n",
            "Epoch 3/19\n",
            "122/122 [==============================] - 36s 291ms/step - loss: 0.2115 - accuracy: 0.9608 - precision: 0.9523 - recall: 0.9700 - val_loss: 1.3644 - val_accuracy: 0.7872 - val_precision: 0.7014 - val_recall: 1.0000\n",
            "Epoch 4/19\n",
            "122/122 [==============================] - 36s 292ms/step - loss: 0.1914 - accuracy: 0.9628 - precision: 0.9628 - recall: 0.9628 - val_loss: 0.1513 - val_accuracy: 0.9711 - val_precision: 0.9524 - val_recall: 0.9917\n",
            "Epoch 5/19\n",
            "122/122 [==============================] - 36s 291ms/step - loss: 0.5528 - accuracy: 0.9138 - precision: 0.9001 - recall: 0.9308 - val_loss: 28.8176 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 6/19\n",
            "122/122 [==============================] - 36s 292ms/step - loss: 0.4726 - accuracy: 0.8669 - precision: 0.8729 - recall: 0.8585 - val_loss: 0.2755 - val_accuracy: 0.9256 - val_precision: 0.9640 - val_recall: 0.8843\n",
            "Epoch 7/19\n",
            "122/122 [==============================] - 37s 301ms/step - loss: 0.2967 - accuracy: 0.9422 - precision: 0.9385 - recall: 0.9463 - val_loss: 0.3622 - val_accuracy: 0.8864 - val_precision: 0.9895 - val_recall: 0.7810\n",
            "Epoch 8/19\n",
            "122/122 [==============================] - 36s 293ms/step - loss: 0.2648 - accuracy: 0.9458 - precision: 0.9499 - recall: 0.9411 - val_loss: 0.5133 - val_accuracy: 0.8285 - val_precision: 1.0000 - val_recall: 0.6570\n",
            "Epoch 9/19\n",
            "122/122 [==============================] - 36s 292ms/step - loss: 0.2740 - accuracy: 0.9551 - precision: 0.9593 - recall: 0.9504 - val_loss: 0.1778 - val_accuracy: 0.9690 - val_precision: 0.9830 - val_recall: 0.9545\n",
            "Epoch 10/19\n",
            "122/122 [==============================] - 36s 293ms/step - loss: 0.3178 - accuracy: 0.9510 - precision: 0.9459 - recall: 0.9566 - val_loss: 0.2062 - val_accuracy: 0.9793 - val_precision: 0.9715 - val_recall: 0.9876\n",
            "Epoch 11/19\n",
            "122/122 [==============================] - 36s 297ms/step - loss: 0.3042 - accuracy: 0.9350 - precision: 0.9287 - recall: 0.9421 - val_loss: 0.2102 - val_accuracy: 0.9649 - val_precision: 0.9956 - val_recall: 0.9339\n",
            "Epoch 12/19\n",
            "122/122 [==============================] - 36s 291ms/step - loss: 0.1991 - accuracy: 0.9696 - precision: 0.9749 - recall: 0.9638 - val_loss: 0.1440 - val_accuracy: 0.9835 - val_precision: 0.9680 - val_recall: 1.0000\n",
            "Epoch 13/19\n",
            "122/122 [==============================] - 36s 291ms/step - loss: 0.3206 - accuracy: 0.9097 - precision: 0.9205 - recall: 0.8967 - val_loss: 1.2937 - val_accuracy: 0.7831 - val_precision: 0.9790 - val_recall: 0.5785\n",
            "Epoch 14/19\n",
            "122/122 [==============================] - 35s 290ms/step - loss: 0.2984 - accuracy: 0.9293 - precision: 0.9453 - recall: 0.9112 - val_loss: 0.2785 - val_accuracy: 0.9091 - val_precision: 1.0000 - val_recall: 0.8182\n",
            "Epoch 15/19\n",
            "122/122 [==============================] - 36s 293ms/step - loss: 0.2506 - accuracy: 0.9567 - precision: 0.9585 - recall: 0.9545 - val_loss: 0.1544 - val_accuracy: 0.9814 - val_precision: 0.9957 - val_recall: 0.9669\n",
            "Epoch 16/19\n",
            "122/122 [==============================] - 37s 299ms/step - loss: 0.1661 - accuracy: 0.9716 - precision: 0.9701 - recall: 0.9731 - val_loss: 0.1278 - val_accuracy: 0.9814 - val_precision: 0.9957 - val_recall: 0.9669\n",
            "Epoch 17/19\n",
            "122/122 [==============================] - 36s 294ms/step - loss: 0.1680 - accuracy: 0.9752 - precision: 0.9822 - recall: 0.9680 - val_loss: 5.3759 - val_accuracy: 0.5041 - val_precision: 0.5021 - val_recall: 1.0000\n",
            "Epoch 18/19\n",
            "122/122 [==============================] - 36s 291ms/step - loss: 0.1498 - accuracy: 0.9788 - precision: 0.9793 - recall: 0.9783 - val_loss: 0.1266 - val_accuracy: 0.9835 - val_precision: 0.9718 - val_recall: 0.9959\n",
            "Epoch 19/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.1785 - accuracy: 0.9778 - precision: 0.9753 - recall: 0.9804 - val_loss: 25.8472 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000\n",
            "\n",
            "Accuracy: 50.00%\n",
            "\n",
            "learning rate: 2.1e-06\n",
            "num_dense_layers: 4\n",
            "num_dense_nodes: 368\n",
            "activation: sigmoid\n",
            "\n",
            "Epoch 1/19\n",
            "122/122 [==============================] - 41s 298ms/step - loss: 0.8641 - accuracy: 0.4995 - precision: 0.4996 - recall: 1.0000 - val_loss: 0.8361 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000\n",
            "Epoch 2/19\n",
            "122/122 [==============================] - 36s 293ms/step - loss: 0.8159 - accuracy: 0.4995 - precision: 0.4995 - recall: 1.0000 - val_loss: 0.7979 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000\n",
            "Epoch 3/19\n",
            "122/122 [==============================] - 36s 292ms/step - loss: 0.7879 - accuracy: 0.4995 - precision: 0.4995 - recall: 1.0000 - val_loss: 0.7760 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000\n",
            "Epoch 4/19\n",
            "122/122 [==============================] - 35s 290ms/step - loss: 0.7712 - accuracy: 0.4995 - precision: 0.4995 - recall: 1.0000 - val_loss: 0.7618 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000\n",
            "Epoch 5/19\n",
            "122/122 [==============================] - 36s 294ms/step - loss: 0.7584 - accuracy: 0.6543 - precision: 0.5911 - recall: 0.9990 - val_loss: 0.7497 - val_accuracy: 0.8554 - val_precision: 0.7774 - val_recall: 0.9959\n",
            "Epoch 6/19\n",
            "122/122 [==============================] - 37s 306ms/step - loss: 0.7468 - accuracy: 0.8875 - precision: 0.8250 - recall: 0.9835 - val_loss: 0.7373 - val_accuracy: 0.9401 - val_precision: 0.9176 - val_recall: 0.9669\n",
            "Epoch 7/19\n",
            "122/122 [==============================] - 46s 377ms/step - loss: 0.7361 - accuracy: 0.9211 - precision: 0.9015 - recall: 0.9452 - val_loss: 0.7244 - val_accuracy: 0.9525 - val_precision: 0.9433 - val_recall: 0.9628\n",
            "Epoch 8/19\n",
            "122/122 [==============================] - 36s 293ms/step - loss: 0.7226 - accuracy: 0.9267 - precision: 0.9155 - recall: 0.9401 - val_loss: 0.7100 - val_accuracy: 0.9566 - val_precision: 0.9547 - val_recall: 0.9587\n",
            "Epoch 9/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.7103 - accuracy: 0.9174 - precision: 0.9191 - recall: 0.9153 - val_loss: 0.6948 - val_accuracy: 0.9566 - val_precision: 0.9547 - val_recall: 0.9587\n",
            "Epoch 10/19\n",
            "122/122 [==============================] - 37s 300ms/step - loss: 0.6935 - accuracy: 0.9329 - precision: 0.9276 - recall: 0.9390 - val_loss: 0.6777 - val_accuracy: 0.9587 - val_precision: 0.9549 - val_recall: 0.9628\n",
            "Epoch 11/19\n",
            "122/122 [==============================] - 36s 293ms/step - loss: 0.6764 - accuracy: 0.9340 - precision: 0.9321 - recall: 0.9360 - val_loss: 0.6598 - val_accuracy: 0.9587 - val_precision: 0.9549 - val_recall: 0.9628\n",
            "Epoch 12/19\n",
            "122/122 [==============================] - 36s 292ms/step - loss: 0.6597 - accuracy: 0.9298 - precision: 0.9228 - recall: 0.9380 - val_loss: 0.6408 - val_accuracy: 0.9587 - val_precision: 0.9549 - val_recall: 0.9628\n",
            "Epoch 13/19\n",
            "122/122 [==============================] - 36s 292ms/step - loss: 0.6414 - accuracy: 0.9288 - precision: 0.9217 - recall: 0.9370 - val_loss: 0.6205 - val_accuracy: 0.9587 - val_precision: 0.9549 - val_recall: 0.9628\n",
            "Epoch 14/19\n",
            "122/122 [==============================] - 38s 312ms/step - loss: 0.6192 - accuracy: 0.9386 - precision: 0.9284 - recall: 0.9504 - val_loss: 0.5984 - val_accuracy: 0.9587 - val_precision: 0.9549 - val_recall: 0.9628\n",
            "Epoch 15/19\n",
            "122/122 [==============================] - 37s 304ms/step - loss: 0.5989 - accuracy: 0.9407 - precision: 0.9356 - recall: 0.9463 - val_loss: 0.5773 - val_accuracy: 0.9587 - val_precision: 0.9549 - val_recall: 0.9628\n",
            "Epoch 16/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.5751 - accuracy: 0.9432 - precision: 0.9378 - recall: 0.9494 - val_loss: 0.5548 - val_accuracy: 0.9566 - val_precision: 0.9547 - val_recall: 0.9587\n",
            "Epoch 17/19\n",
            "122/122 [==============================] - 37s 299ms/step - loss: 0.5539 - accuracy: 0.9432 - precision: 0.9414 - recall: 0.9452 - val_loss: 0.5309 - val_accuracy: 0.9587 - val_precision: 0.9549 - val_recall: 0.9628\n",
            "Epoch 18/19\n",
            "122/122 [==============================] - 36s 295ms/step - loss: 0.5361 - accuracy: 0.9355 - precision: 0.9253 - recall: 0.9473 - val_loss: 0.5083 - val_accuracy: 0.9566 - val_precision: 0.9547 - val_recall: 0.9587\n",
            "Epoch 19/19\n",
            "122/122 [==============================] - 36s 293ms/step - loss: 0.5112 - accuracy: 0.9448 - precision: 0.9388 - recall: 0.9514 - val_loss: 0.4862 - val_accuracy: 0.9607 - val_precision: 0.9551 - val_recall: 0.9669\n",
            "\n",
            "Accuracy: 96.07%\n",
            "\n",
            "learning rate: 2.4e-05\n",
            "num_dense_layers: 1\n",
            "num_dense_nodes: 497\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/19\n",
            "122/122 [==============================] - 41s 299ms/step - loss: 0.3292 - accuracy: 0.9164 - precision: 0.9356 - recall: 0.9132 - val_loss: 0.2054 - val_accuracy: 0.9607 - val_precision: 0.9588 - val_recall: 0.9628\n",
            "Epoch 2/19\n",
            "122/122 [==============================] - 36s 291ms/step - loss: 0.2520 - accuracy: 0.9438 - precision: 0.9479 - recall: 0.9390 - val_loss: 0.2092 - val_accuracy: 0.9566 - val_precision: 0.9547 - val_recall: 0.9587\n",
            "Epoch 3/19\n",
            "122/122 [==============================] - 36s 292ms/step - loss: 0.2524 - accuracy: 0.9479 - precision: 0.9419 - recall: 0.9545 - val_loss: 0.1964 - val_accuracy: 0.9669 - val_precision: 0.9593 - val_recall: 0.9752\n",
            "Epoch 4/19\n",
            "122/122 [==============================] - 36s 293ms/step - loss: 0.2333 - accuracy: 0.9536 - precision: 0.9425 - recall: 0.9659 - val_loss: 0.1866 - val_accuracy: 0.9628 - val_precision: 0.9628 - val_recall: 0.9628\n",
            "Epoch 5/19\n",
            "122/122 [==============================] - 37s 302ms/step - loss: 0.2252 - accuracy: 0.9598 - precision: 0.9588 - recall: 0.9607 - val_loss: 0.5520 - val_accuracy: 0.9070 - val_precision: 0.9539 - val_recall: 0.8554\n",
            "Epoch 6/19\n",
            "122/122 [==============================] - 36s 295ms/step - loss: 0.2231 - accuracy: 0.9603 - precision: 0.9636 - recall: 0.9566 - val_loss: 0.1792 - val_accuracy: 0.9690 - val_precision: 0.9558 - val_recall: 0.9835\n",
            "Epoch 7/19\n",
            "122/122 [==============================] - 36s 293ms/step - loss: 0.2186 - accuracy: 0.9592 - precision: 0.9522 - recall: 0.9669 - val_loss: 0.1731 - val_accuracy: 0.9752 - val_precision: 0.9600 - val_recall: 0.9917\n",
            "Epoch 8/19\n",
            "122/122 [==============================] - 36s 291ms/step - loss: 0.2070 - accuracy: 0.9592 - precision: 0.9540 - recall: 0.9649 - val_loss: 0.1741 - val_accuracy: 0.9731 - val_precision: 0.9673 - val_recall: 0.9793\n",
            "Epoch 9/19\n",
            "122/122 [==============================] - 36s 295ms/step - loss: 0.1966 - accuracy: 0.9639 - precision: 0.9619 - recall: 0.9659 - val_loss: 0.2030 - val_accuracy: 0.9669 - val_precision: 0.9593 - val_recall: 0.9752\n",
            "Epoch 10/19\n",
            "122/122 [==============================] - 36s 294ms/step - loss: 0.1829 - accuracy: 0.9659 - precision: 0.9659 - recall: 0.9659 - val_loss: 0.2802 - val_accuracy: 0.9525 - val_precision: 0.9620 - val_recall: 0.9421\n",
            "Epoch 11/19\n",
            "122/122 [==============================] - 36s 294ms/step - loss: 0.1990 - accuracy: 0.9634 - precision: 0.9600 - recall: 0.9669 - val_loss: 0.1550 - val_accuracy: 0.9814 - val_precision: 0.9679 - val_recall: 0.9959\n",
            "Epoch 12/19\n",
            "122/122 [==============================] - 36s 293ms/step - loss: 0.1770 - accuracy: 0.9706 - precision: 0.9672 - recall: 0.9742 - val_loss: 0.6524 - val_accuracy: 0.9256 - val_precision: 0.9640 - val_recall: 0.8843\n",
            "Epoch 13/19\n",
            "122/122 [==============================] - 36s 294ms/step - loss: 0.2019 - accuracy: 0.9623 - precision: 0.9609 - recall: 0.9638 - val_loss: 0.1532 - val_accuracy: 0.9814 - val_precision: 0.9679 - val_recall: 0.9959\n",
            "Epoch 14/19\n",
            "122/122 [==============================] - 37s 303ms/step - loss: 0.1709 - accuracy: 0.9716 - precision: 0.9711 - recall: 0.9721 - val_loss: 0.1602 - val_accuracy: 0.9773 - val_precision: 0.9676 - val_recall: 0.9876\n",
            "Epoch 15/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.1749 - accuracy: 0.9727 - precision: 0.9683 - recall: 0.9773 - val_loss: 0.2063 - val_accuracy: 0.9669 - val_precision: 0.9669 - val_recall: 0.9669\n",
            "Epoch 16/19\n",
            "122/122 [==============================] - 36s 293ms/step - loss: 0.1802 - accuracy: 0.9690 - precision: 0.9604 - recall: 0.9783 - val_loss: 0.1609 - val_accuracy: 0.9773 - val_precision: 0.9714 - val_recall: 0.9835\n",
            "Epoch 17/19\n",
            "122/122 [==============================] - 36s 292ms/step - loss: 0.1596 - accuracy: 0.9716 - precision: 0.9750 - recall: 0.9680 - val_loss: 0.1453 - val_accuracy: 0.9814 - val_precision: 0.9679 - val_recall: 0.9959\n",
            "Epoch 18/19\n",
            "122/122 [==============================] - 36s 293ms/step - loss: 0.1565 - accuracy: 0.9799 - precision: 0.9764 - recall: 0.9835 - val_loss: 0.1421 - val_accuracy: 0.9814 - val_precision: 0.9717 - val_recall: 0.9917\n",
            "Epoch 19/19\n",
            "122/122 [==============================] - 36s 293ms/step - loss: 0.1701 - accuracy: 0.9747 - precision: 0.9772 - recall: 0.9721 - val_loss: 0.1440 - val_accuracy: 0.9835 - val_precision: 0.9718 - val_recall: 0.9959\n",
            "\n",
            "Accuracy: 98.35%\n",
            "\n",
            "learning rate: 5.4e-04\n",
            "num_dense_layers: 4\n",
            "num_dense_nodes: 256\n",
            "activation: sigmoid\n",
            "\n",
            "Epoch 1/19\n",
            "122/122 [==============================] - 41s 301ms/step - loss: 0.3092 - accuracy: 0.9309 - precision: 0.9370 - recall: 0.9463 - val_loss: 0.2679 - val_accuracy: 0.9339 - val_precision: 0.8832 - val_recall: 1.0000\n",
            "Epoch 2/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.2029 - accuracy: 0.9665 - precision: 0.9584 - recall: 0.9752 - val_loss: 0.1410 - val_accuracy: 0.9835 - val_precision: 0.9875 - val_recall: 0.9793\n",
            "Epoch 3/19\n",
            "122/122 [==============================] - 38s 313ms/step - loss: 0.1622 - accuracy: 0.9716 - precision: 0.9682 - recall: 0.9752 - val_loss: 0.1317 - val_accuracy: 0.9793 - val_precision: 0.9603 - val_recall: 1.0000\n",
            "Epoch 4/19\n",
            "122/122 [==============================] - 36s 295ms/step - loss: 0.1517 - accuracy: 0.9778 - precision: 0.9773 - recall: 0.9783 - val_loss: 0.0975 - val_accuracy: 0.9897 - val_precision: 0.9877 - val_recall: 0.9917\n",
            "Epoch 5/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.1133 - accuracy: 0.9876 - precision: 0.9886 - recall: 0.9866 - val_loss: 0.0951 - val_accuracy: 0.9897 - val_precision: 0.9798 - val_recall: 1.0000\n",
            "Epoch 6/19\n",
            "122/122 [==============================] - 36s 293ms/step - loss: 0.1009 - accuracy: 0.9892 - precision: 0.9886 - recall: 0.9897 - val_loss: 0.1617 - val_accuracy: 0.9711 - val_precision: 0.9453 - val_recall: 1.0000\n",
            "Epoch 7/19\n",
            "122/122 [==============================] - 36s 293ms/step - loss: 0.0939 - accuracy: 0.9907 - precision: 0.9897 - recall: 0.9917 - val_loss: 0.0896 - val_accuracy: 0.9917 - val_precision: 0.9837 - val_recall: 1.0000\n",
            "Epoch 8/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.0985 - accuracy: 0.9912 - precision: 0.9927 - recall: 0.9897 - val_loss: 0.1524 - val_accuracy: 0.9690 - val_precision: 0.9522 - val_recall: 0.9876\n",
            "Epoch 9/19\n",
            "122/122 [==============================] - 36s 294ms/step - loss: 0.1381 - accuracy: 0.9763 - precision: 0.9743 - recall: 0.9783 - val_loss: 0.0897 - val_accuracy: 0.9876 - val_precision: 0.9797 - val_recall: 0.9959\n",
            "Epoch 10/19\n",
            "122/122 [==============================] - 36s 295ms/step - loss: 0.1343 - accuracy: 0.9809 - precision: 0.9844 - recall: 0.9773 - val_loss: 0.1202 - val_accuracy: 0.9752 - val_precision: 0.9873 - val_recall: 0.9628\n",
            "Epoch 11/19\n",
            "122/122 [==============================] - 36s 295ms/step - loss: 0.1176 - accuracy: 0.9861 - precision: 0.9886 - recall: 0.9835 - val_loss: 0.1013 - val_accuracy: 0.9876 - val_precision: 0.9836 - val_recall: 0.9917\n",
            "Epoch 12/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.1227 - accuracy: 0.9814 - precision: 0.9824 - recall: 0.9804 - val_loss: 0.0857 - val_accuracy: 0.9897 - val_precision: 0.9877 - val_recall: 0.9917\n",
            "Epoch 13/19\n",
            "122/122 [==============================] - 37s 300ms/step - loss: 0.1069 - accuracy: 0.9881 - precision: 0.9886 - recall: 0.9876 - val_loss: 0.0973 - val_accuracy: 0.9938 - val_precision: 0.9878 - val_recall: 1.0000\n",
            "Epoch 14/19\n",
            "122/122 [==============================] - 36s 295ms/step - loss: 0.0785 - accuracy: 0.9959 - precision: 0.9948 - recall: 0.9969 - val_loss: 0.0894 - val_accuracy: 0.9917 - val_precision: 0.9837 - val_recall: 1.0000\n",
            "Epoch 15/19\n",
            "122/122 [==============================] - 36s 294ms/step - loss: 0.0813 - accuracy: 0.9928 - precision: 0.9928 - recall: 0.9928 - val_loss: 0.2764 - val_accuracy: 0.9153 - val_precision: 0.8551 - val_recall: 1.0000\n",
            "Epoch 16/19\n",
            "122/122 [==============================] - 36s 295ms/step - loss: 0.0808 - accuracy: 0.9923 - precision: 0.9907 - recall: 0.9938 - val_loss: 0.0750 - val_accuracy: 0.9959 - val_precision: 0.9918 - val_recall: 1.0000\n",
            "Epoch 17/19\n",
            "122/122 [==============================] - 38s 308ms/step - loss: 0.0770 - accuracy: 0.9943 - precision: 0.9969 - recall: 0.9917 - val_loss: 0.0966 - val_accuracy: 0.9835 - val_precision: 0.9875 - val_recall: 0.9793\n",
            "Epoch 18/19\n",
            "122/122 [==============================] - 36s 295ms/step - loss: 0.1142 - accuracy: 0.9835 - precision: 0.9875 - recall: 0.9793 - val_loss: 0.0734 - val_accuracy: 0.9959 - val_precision: 0.9918 - val_recall: 1.0000\n",
            "Epoch 19/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.0928 - accuracy: 0.9892 - precision: 0.9886 - recall: 0.9897 - val_loss: 0.2127 - val_accuracy: 0.9566 - val_precision: 0.9202 - val_recall: 1.0000\n",
            "\n",
            "Accuracy: 95.66%\n",
            "\n",
            "learning rate: 8.1e-06\n",
            "num_dense_layers: 1\n",
            "num_dense_nodes: 351\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/19\n",
            "122/122 [==============================] - 42s 301ms/step - loss: 0.2858 - accuracy: 0.9386 - precision: 0.8987 - recall: 0.9967 - val_loss: 0.1210 - val_accuracy: 0.9979 - val_precision: 0.9959 - val_recall: 1.0000\n",
            "Epoch 2/19\n",
            "122/122 [==============================] - 38s 309ms/step - loss: 0.1104 - accuracy: 0.9979 - precision: 0.9969 - recall: 0.9990 - val_loss: 0.0846 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 3/19\n",
            "122/122 [==============================] - 36s 295ms/step - loss: 0.0901 - accuracy: 0.9943 - precision: 0.9938 - recall: 0.9948 - val_loss: 0.0720 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 4/19\n",
            "122/122 [==============================] - 36s 294ms/step - loss: 0.0804 - accuracy: 0.9959 - precision: 0.9969 - recall: 0.9948 - val_loss: 0.0672 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 5/19\n",
            "122/122 [==============================] - 36s 293ms/step - loss: 0.0741 - accuracy: 0.9964 - precision: 0.9969 - recall: 0.9959 - val_loss: 0.0640 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 6/19\n",
            "122/122 [==============================] - 36s 292ms/step - loss: 0.0758 - accuracy: 0.9943 - precision: 0.9959 - recall: 0.9928 - val_loss: 0.0629 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 7/19\n",
            "122/122 [==============================] - 36s 292ms/step - loss: 0.0811 - accuracy: 0.9948 - precision: 0.9959 - recall: 0.9938 - val_loss: 0.0634 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 8/19\n",
            "122/122 [==============================] - 36s 293ms/step - loss: 0.0670 - accuracy: 0.9985 - precision: 0.9979 - recall: 0.9990 - val_loss: 0.0616 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 9/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.0703 - accuracy: 0.9954 - precision: 0.9979 - recall: 0.9928 - val_loss: 0.0603 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 10/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.0720 - accuracy: 0.9959 - precision: 0.9948 - recall: 0.9969 - val_loss: 0.0601 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 11/19\n",
            "122/122 [==============================] - 38s 309ms/step - loss: 0.0667 - accuracy: 0.9969 - precision: 0.9990 - recall: 0.9948 - val_loss: 0.0594 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 12/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.0723 - accuracy: 0.9974 - precision: 0.9979 - recall: 0.9969 - val_loss: 0.0611 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 13/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.0722 - accuracy: 0.9964 - precision: 0.9979 - recall: 0.9948 - val_loss: 0.0636 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 14/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.0693 - accuracy: 0.9974 - precision: 0.9990 - recall: 0.9959 - val_loss: 0.0610 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 15/19\n",
            "122/122 [==============================] - 36s 297ms/step - loss: 0.0770 - accuracy: 0.9954 - precision: 0.9969 - recall: 0.9938 - val_loss: 0.0608 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 16/19\n",
            "122/122 [==============================] - 36s 297ms/step - loss: 0.0655 - accuracy: 0.9964 - precision: 0.9979 - recall: 0.9948 - val_loss: 0.0593 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 17/19\n",
            "122/122 [==============================] - 36s 293ms/step - loss: 0.0686 - accuracy: 0.9948 - precision: 0.9979 - recall: 0.9917 - val_loss: 0.0585 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 18/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.0631 - accuracy: 0.9974 - precision: 0.9979 - recall: 0.9969 - val_loss: 0.0580 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "Epoch 19/19\n",
            "122/122 [==============================] - 36s 297ms/step - loss: 0.0719 - accuracy: 0.9943 - precision: 0.9979 - recall: 0.9907 - val_loss: 0.0595 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
            "\n",
            "Accuracy: 100.00%\n",
            "\n",
            "learning rate: 2.2e-03\n",
            "num_dense_layers: 3\n",
            "num_dense_nodes: 30\n",
            "activation: sigmoid\n",
            "\n",
            "Epoch 1/19\n",
            "122/122 [==============================] - 43s 314ms/step - loss: 0.3969 - accuracy: 0.9004 - precision: 0.9298 - recall: 0.9091 - val_loss: 0.3996 - val_accuracy: 0.8450 - val_precision: 0.7702 - val_recall: 0.9835\n",
            "Epoch 2/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.3487 - accuracy: 0.9112 - precision: 0.9045 - recall: 0.9194 - val_loss: 0.4093 - val_accuracy: 0.8843 - val_precision: 0.9697 - val_recall: 0.7934\n",
            "Epoch 3/19\n",
            "122/122 [==============================] - 36s 295ms/step - loss: 0.2592 - accuracy: 0.9345 - precision: 0.9412 - recall: 0.9267 - val_loss: 0.7286 - val_accuracy: 0.7955 - val_precision: 0.9613 - val_recall: 0.6157\n",
            "Epoch 4/19\n",
            "122/122 [==============================] - 36s 294ms/step - loss: 0.2625 - accuracy: 0.9298 - precision: 0.9160 - recall: 0.9463 - val_loss: 0.4671 - val_accuracy: 0.8802 - val_precision: 0.8067 - val_recall: 1.0000\n",
            "Epoch 5/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.2308 - accuracy: 0.9412 - precision: 0.9543 - recall: 0.9267 - val_loss: 0.3986 - val_accuracy: 0.8822 - val_precision: 0.9894 - val_recall: 0.7727\n",
            "Epoch 6/19\n",
            "122/122 [==============================] - 36s 295ms/step - loss: 0.1979 - accuracy: 0.9587 - precision: 0.9540 - recall: 0.9638 - val_loss: 0.3089 - val_accuracy: 0.9132 - val_precision: 0.8968 - val_recall: 0.9339\n",
            "Epoch 7/19\n",
            "122/122 [==============================] - 36s 299ms/step - loss: 0.2061 - accuracy: 0.9469 - precision: 0.9548 - recall: 0.9380 - val_loss: 0.6269 - val_accuracy: 0.7996 - val_precision: 1.0000 - val_recall: 0.5992\n",
            "Epoch 8/19\n",
            "122/122 [==============================] - 36s 295ms/step - loss: 0.2138 - accuracy: 0.9505 - precision: 0.9504 - recall: 0.9504 - val_loss: 0.2192 - val_accuracy: 0.9483 - val_precision: 0.9255 - val_recall: 0.9752\n",
            "Epoch 9/19\n",
            "122/122 [==============================] - 36s 298ms/step - loss: 0.2688 - accuracy: 0.9241 - precision: 0.9362 - recall: 0.9101 - val_loss: 1.3322 - val_accuracy: 0.6674 - val_precision: 0.9765 - val_recall: 0.3430\n",
            "Epoch 10/19\n",
            "122/122 [==============================] - 37s 306ms/step - loss: 0.2286 - accuracy: 0.9360 - precision: 0.9489 - recall: 0.9215 - val_loss: 0.2505 - val_accuracy: 0.9339 - val_precision: 0.9907 - val_recall: 0.8760\n",
            "Epoch 11/19\n",
            "122/122 [==============================] - 36s 295ms/step - loss: 0.3691 - accuracy: 0.8725 - precision: 0.8767 - recall: 0.8667 - val_loss: 0.6761 - val_accuracy: 0.7417 - val_precision: 0.9916 - val_recall: 0.4876\n",
            "Epoch 12/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.3725 - accuracy: 0.8818 - precision: 0.8918 - recall: 0.8688 - val_loss: 0.6181 - val_accuracy: 0.8678 - val_precision: 0.8027 - val_recall: 0.9752\n",
            "Epoch 13/19\n",
            "122/122 [==============================] - 36s 295ms/step - loss: 0.2624 - accuracy: 0.9267 - precision: 0.9499 - recall: 0.9008 - val_loss: 0.1878 - val_accuracy: 0.9649 - val_precision: 0.9518 - val_recall: 0.9793\n",
            "Epoch 14/19\n",
            "122/122 [==============================] - 36s 294ms/step - loss: 0.2285 - accuracy: 0.9438 - precision: 0.9432 - recall: 0.9442 - val_loss: 0.3874 - val_accuracy: 0.8843 - val_precision: 0.8142 - val_recall: 0.9959\n",
            "Epoch 15/19\n",
            "122/122 [==============================] - 36s 295ms/step - loss: 0.2713 - accuracy: 0.9226 - precision: 0.9225 - recall: 0.9225 - val_loss: 0.8496 - val_accuracy: 0.7335 - val_precision: 1.0000 - val_recall: 0.4669\n",
            "Epoch 16/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.2308 - accuracy: 0.9469 - precision: 0.9519 - recall: 0.9411 - val_loss: 0.2312 - val_accuracy: 0.9504 - val_precision: 0.9739 - val_recall: 0.9256\n",
            "Epoch 17/19\n",
            "122/122 [==============================] - 37s 299ms/step - loss: 0.1718 - accuracy: 0.9701 - precision: 0.9700 - recall: 0.9700 - val_loss: 0.1109 - val_accuracy: 0.9917 - val_precision: 0.9877 - val_recall: 0.9959\n",
            "Epoch 18/19\n",
            "122/122 [==============================] - 36s 298ms/step - loss: 0.1552 - accuracy: 0.9716 - precision: 0.9731 - recall: 0.9700 - val_loss: 0.2126 - val_accuracy: 0.9545 - val_precision: 0.9167 - val_recall: 1.0000\n",
            "Epoch 19/19\n",
            "122/122 [==============================] - 37s 297ms/step - loss: 0.1697 - accuracy: 0.9690 - precision: 0.9749 - recall: 0.9628 - val_loss: 0.2515 - val_accuracy: 0.9318 - val_precision: 0.8800 - val_recall: 1.0000\n",
            "\n",
            "Accuracy: 93.18%\n",
            "\n",
            "learning rate: 1.0e-03\n",
            "num_dense_layers: 2\n",
            "num_dense_nodes: 382\n",
            "activation: sigmoid\n",
            "\n",
            "Epoch 1/19\n",
            "122/122 [==============================] - 42s 305ms/step - loss: 0.1562 - accuracy: 0.9716 - precision: 0.9488 - recall: 0.9802 - val_loss: 0.1317 - val_accuracy: 0.9731 - val_precision: 0.9598 - val_recall: 0.9876\n",
            "Epoch 2/19\n",
            "122/122 [==============================] - 37s 300ms/step - loss: 0.1135 - accuracy: 0.9830 - precision: 0.9865 - recall: 0.9793 - val_loss: 0.2183 - val_accuracy: 0.9339 - val_precision: 0.8832 - val_recall: 1.0000\n",
            "Epoch 3/19\n",
            "122/122 [==============================] - 36s 298ms/step - loss: 0.1187 - accuracy: 0.9778 - precision: 0.9734 - recall: 0.9824 - val_loss: 0.0919 - val_accuracy: 0.9897 - val_precision: 0.9877 - val_recall: 0.9917\n",
            "Epoch 4/19\n",
            "122/122 [==============================] - 36s 298ms/step - loss: 0.1866 - accuracy: 0.9541 - precision: 0.9564 - recall: 0.9514 - val_loss: 0.1481 - val_accuracy: 0.9566 - val_precision: 0.9202 - val_recall: 1.0000\n",
            "Epoch 5/19\n",
            "122/122 [==============================] - 36s 297ms/step - loss: 0.1148 - accuracy: 0.9825 - precision: 0.9814 - recall: 0.9835 - val_loss: 0.1540 - val_accuracy: 0.9504 - val_precision: 0.9129 - val_recall: 0.9959\n",
            "Epoch 6/19\n",
            "122/122 [==============================] - 37s 302ms/step - loss: 0.0830 - accuracy: 0.9907 - precision: 0.9887 - recall: 0.9928 - val_loss: 0.0804 - val_accuracy: 0.9835 - val_precision: 0.9718 - val_recall: 0.9959\n",
            "Epoch 7/19\n",
            "122/122 [==============================] - 36s 297ms/step - loss: 0.0762 - accuracy: 0.9943 - precision: 0.9938 - recall: 0.9948 - val_loss: 0.0746 - val_accuracy: 0.9876 - val_precision: 0.9797 - val_recall: 0.9959\n",
            "Epoch 8/19\n",
            "122/122 [==============================] - 38s 307ms/step - loss: 0.0944 - accuracy: 0.9856 - precision: 0.9876 - recall: 0.9835 - val_loss: 0.1935 - val_accuracy: 0.9360 - val_precision: 0.8893 - val_recall: 0.9959\n",
            "Epoch 9/19\n",
            "122/122 [==============================] - 36s 297ms/step - loss: 0.0634 - accuracy: 0.9959 - precision: 0.9979 - recall: 0.9938 - val_loss: 0.1113 - val_accuracy: 0.9793 - val_precision: 0.9603 - val_recall: 1.0000\n",
            "Epoch 10/19\n",
            "122/122 [==============================] - 36s 297ms/step - loss: 0.0849 - accuracy: 0.9892 - precision: 0.9897 - recall: 0.9886 - val_loss: 0.6384 - val_accuracy: 0.8554 - val_precision: 0.7756 - val_recall: 1.0000\n",
            "Epoch 11/19\n",
            "122/122 [==============================] - 36s 295ms/step - loss: 0.0771 - accuracy: 0.9871 - precision: 0.9876 - recall: 0.9866 - val_loss: 0.0796 - val_accuracy: 0.9876 - val_precision: 0.9758 - val_recall: 1.0000\n",
            "Epoch 12/19\n",
            "122/122 [==============================] - 36s 297ms/step - loss: 0.1639 - accuracy: 0.9665 - precision: 0.9602 - recall: 0.9731 - val_loss: 0.0924 - val_accuracy: 0.9959 - val_precision: 0.9959 - val_recall: 0.9959\n",
            "Epoch 13/19\n",
            "122/122 [==============================] - 36s 298ms/step - loss: 0.0947 - accuracy: 0.9871 - precision: 0.9886 - recall: 0.9855 - val_loss: 0.0862 - val_accuracy: 0.9959 - val_precision: 0.9918 - val_recall: 1.0000\n",
            "Epoch 14/19\n",
            "122/122 [==============================] - 36s 298ms/step - loss: 0.0918 - accuracy: 0.9892 - precision: 0.9907 - recall: 0.9876 - val_loss: 0.0770 - val_accuracy: 0.9938 - val_precision: 0.9878 - val_recall: 1.0000\n",
            "Epoch 15/19\n",
            "122/122 [==============================] - 37s 299ms/step - loss: 0.1040 - accuracy: 0.9871 - precision: 0.9856 - recall: 0.9886 - val_loss: 0.0754 - val_accuracy: 0.9917 - val_precision: 1.0000 - val_recall: 0.9835\n",
            "Epoch 16/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.1008 - accuracy: 0.9876 - precision: 0.9856 - recall: 0.9897 - val_loss: 0.1723 - val_accuracy: 0.9421 - val_precision: 0.8963 - val_recall: 1.0000\n",
            "Epoch 17/19\n",
            "122/122 [==============================] - 38s 307ms/step - loss: 0.1050 - accuracy: 0.9819 - precision: 0.9854 - recall: 0.9783 - val_loss: 0.1204 - val_accuracy: 0.9835 - val_precision: 0.9680 - val_recall: 1.0000\n",
            "Epoch 18/19\n",
            "122/122 [==============================] - 36s 295ms/step - loss: 0.0798 - accuracy: 0.9907 - precision: 0.9907 - recall: 0.9907 - val_loss: 0.1788 - val_accuracy: 0.9587 - val_precision: 0.9237 - val_recall: 1.0000\n",
            "Epoch 19/19\n",
            "122/122 [==============================] - 36s 298ms/step - loss: 0.0863 - accuracy: 0.9892 - precision: 0.9876 - recall: 0.9907 - val_loss: 0.0826 - val_accuracy: 0.9959 - val_precision: 0.9918 - val_recall: 1.0000\n",
            "\n",
            "Accuracy: 99.59%\n",
            "\n",
            "learning rate: 9.2e-04\n",
            "num_dense_layers: 2\n",
            "num_dense_nodes: 475\n",
            "activation: sigmoid\n",
            "\n",
            "Epoch 1/19\n",
            "122/122 [==============================] - 42s 304ms/step - loss: 0.0973 - accuracy: 0.9876 - precision: 0.9852 - recall: 0.9934 - val_loss: 0.0704 - val_accuracy: 0.9897 - val_precision: 0.9917 - val_recall: 0.9876\n",
            "Epoch 2/19\n",
            "122/122 [==============================] - 36s 298ms/step - loss: 0.0937 - accuracy: 0.9881 - precision: 0.9886 - recall: 0.9876 - val_loss: 0.1182 - val_accuracy: 0.9731 - val_precision: 0.9526 - val_recall: 0.9959\n",
            "Epoch 3/19\n",
            "122/122 [==============================] - 36s 295ms/step - loss: 0.0909 - accuracy: 0.9840 - precision: 0.9875 - recall: 0.9804 - val_loss: 0.5321 - val_accuracy: 0.8822 - val_precision: 0.8094 - val_recall: 1.0000\n",
            "Epoch 4/19\n",
            "122/122 [==============================] - 37s 299ms/step - loss: 0.0764 - accuracy: 0.9907 - precision: 0.9917 - recall: 0.9897 - val_loss: 0.0704 - val_accuracy: 0.9959 - val_precision: 0.9918 - val_recall: 1.0000\n",
            "Epoch 5/19\n",
            "122/122 [==============================] - 37s 299ms/step - loss: 0.0835 - accuracy: 0.9897 - precision: 0.9907 - recall: 0.9886 - val_loss: 0.1578 - val_accuracy: 0.9607 - val_precision: 0.9272 - val_recall: 1.0000\n",
            "Epoch 6/19\n",
            "122/122 [==============================] - 38s 307ms/step - loss: 0.0810 - accuracy: 0.9881 - precision: 0.9876 - recall: 0.9886 - val_loss: 0.2026 - val_accuracy: 0.9690 - val_precision: 0.9956 - val_recall: 0.9421\n",
            "Epoch 7/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.0957 - accuracy: 0.9830 - precision: 0.9785 - recall: 0.9876 - val_loss: 0.2504 - val_accuracy: 0.9545 - val_precision: 1.0000 - val_recall: 0.9091\n",
            "Epoch 8/19\n",
            "122/122 [==============================] - 36s 297ms/step - loss: 0.0844 - accuracy: 0.9912 - precision: 0.9917 - recall: 0.9907 - val_loss: 0.1231 - val_accuracy: 0.9628 - val_precision: 0.9308 - val_recall: 1.0000\n",
            "Epoch 9/19\n",
            "122/122 [==============================] - 36s 298ms/step - loss: 0.0736 - accuracy: 0.9902 - precision: 0.9857 - recall: 0.9948 - val_loss: 0.0705 - val_accuracy: 0.9938 - val_precision: 0.9918 - val_recall: 0.9959\n",
            "Epoch 10/19\n",
            "122/122 [==============================] - 36s 297ms/step - loss: 0.0819 - accuracy: 0.9907 - precision: 0.9979 - recall: 0.9835 - val_loss: 0.2855 - val_accuracy: 0.9008 - val_precision: 0.8345 - val_recall: 1.0000\n",
            "Epoch 11/19\n",
            "122/122 [==============================] - 36s 297ms/step - loss: 0.0921 - accuracy: 0.9886 - precision: 0.9866 - recall: 0.9907 - val_loss: 0.3323 - val_accuracy: 0.8843 - val_precision: 0.8121 - val_recall: 1.0000\n",
            "Epoch 12/19\n",
            "122/122 [==============================] - 36s 297ms/step - loss: 0.0635 - accuracy: 0.9948 - precision: 0.9948 - recall: 0.9948 - val_loss: 0.0729 - val_accuracy: 0.9897 - val_precision: 0.9837 - val_recall: 0.9959\n",
            "Epoch 13/19\n",
            "122/122 [==============================] - 37s 299ms/step - loss: 0.0465 - accuracy: 0.9990 - precision: 0.9990 - recall: 0.9990 - val_loss: 0.0630 - val_accuracy: 0.9938 - val_precision: 0.9918 - val_recall: 0.9959\n",
            "Epoch 14/19\n",
            "122/122 [==============================] - 38s 307ms/step - loss: 0.0816 - accuracy: 0.9845 - precision: 0.9885 - recall: 0.9804 - val_loss: 0.1241 - val_accuracy: 0.9669 - val_precision: 0.9913 - val_recall: 0.9421\n",
            "Epoch 15/19\n",
            "122/122 [==============================] - 36s 295ms/step - loss: 0.0720 - accuracy: 0.9907 - precision: 0.9887 - recall: 0.9928 - val_loss: 0.0880 - val_accuracy: 0.9876 - val_precision: 0.9797 - val_recall: 0.9959\n",
            "Epoch 16/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.0616 - accuracy: 0.9933 - precision: 0.9928 - recall: 0.9938 - val_loss: 0.0703 - val_accuracy: 0.9938 - val_precision: 0.9878 - val_recall: 1.0000\n",
            "Epoch 17/19\n",
            "122/122 [==============================] - 36s 298ms/step - loss: 0.0632 - accuracy: 0.9948 - precision: 0.9938 - recall: 0.9959 - val_loss: 0.0909 - val_accuracy: 0.9752 - val_precision: 0.9563 - val_recall: 0.9959\n",
            "Epoch 18/19\n",
            "122/122 [==============================] - 36s 295ms/step - loss: 0.0967 - accuracy: 0.9830 - precision: 0.9795 - recall: 0.9866 - val_loss: 0.0848 - val_accuracy: 0.9917 - val_precision: 1.0000 - val_recall: 0.9835\n",
            "Epoch 19/19\n",
            "122/122 [==============================] - 36s 294ms/step - loss: 0.0980 - accuracy: 0.9850 - precision: 0.9855 - recall: 0.9845 - val_loss: 0.0961 - val_accuracy: 0.9835 - val_precision: 0.9680 - val_recall: 1.0000\n",
            "\n",
            "Accuracy: 98.35%\n",
            "\n",
            "learning rate: 9.0e-06\n",
            "num_dense_layers: 1\n",
            "num_dense_nodes: 450\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/19\n",
            "122/122 [==============================] - 42s 304ms/step - loss: 0.6458 - accuracy: 0.8354 - precision: 0.8111 - recall: 0.9512 - val_loss: 0.1341 - val_accuracy: 0.9814 - val_precision: 0.9641 - val_recall: 1.0000\n",
            "Epoch 2/19\n",
            "122/122 [==============================] - 36s 297ms/step - loss: 0.1016 - accuracy: 0.9948 - precision: 0.9908 - recall: 0.9990 - val_loss: 0.1015 - val_accuracy: 0.9835 - val_precision: 0.9718 - val_recall: 0.9959\n",
            "Epoch 3/19\n",
            "122/122 [==============================] - 38s 307ms/step - loss: 0.0823 - accuracy: 0.9923 - precision: 0.9877 - recall: 0.9969 - val_loss: 0.0852 - val_accuracy: 0.9835 - val_precision: 0.9718 - val_recall: 0.9959\n",
            "Epoch 4/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.0771 - accuracy: 0.9917 - precision: 0.9887 - recall: 0.9948 - val_loss: 0.0797 - val_accuracy: 0.9855 - val_precision: 0.9757 - val_recall: 0.9959\n",
            "Epoch 5/19\n",
            "122/122 [==============================] - 36s 298ms/step - loss: 0.0693 - accuracy: 0.9928 - precision: 0.9867 - recall: 0.9990 - val_loss: 0.0748 - val_accuracy: 0.9876 - val_precision: 0.9797 - val_recall: 0.9959\n",
            "Epoch 6/19\n",
            "122/122 [==============================] - 36s 298ms/step - loss: 0.0642 - accuracy: 0.9954 - precision: 0.9938 - recall: 0.9969 - val_loss: 0.0711 - val_accuracy: 0.9897 - val_precision: 0.9837 - val_recall: 0.9959\n",
            "Epoch 7/19\n",
            "122/122 [==============================] - 36s 297ms/step - loss: 0.0616 - accuracy: 0.9969 - precision: 0.9949 - recall: 0.9990 - val_loss: 0.0696 - val_accuracy: 0.9917 - val_precision: 0.9877 - val_recall: 0.9959\n",
            "Epoch 8/19\n",
            "122/122 [==============================] - 36s 298ms/step - loss: 0.0601 - accuracy: 0.9954 - precision: 0.9928 - recall: 0.9979 - val_loss: 0.0663 - val_accuracy: 0.9917 - val_precision: 0.9877 - val_recall: 0.9959\n",
            "Epoch 9/19\n",
            "122/122 [==============================] - 36s 298ms/step - loss: 0.0664 - accuracy: 0.9959 - precision: 0.9959 - recall: 0.9959 - val_loss: 0.0656 - val_accuracy: 0.9917 - val_precision: 0.9877 - val_recall: 0.9959\n",
            "Epoch 10/19\n",
            "122/122 [==============================] - 37s 303ms/step - loss: 0.0576 - accuracy: 0.9964 - precision: 0.9969 - recall: 0.9959 - val_loss: 0.0666 - val_accuracy: 0.9917 - val_precision: 0.9877 - val_recall: 0.9959\n",
            "Epoch 11/19\n",
            "122/122 [==============================] - 36s 297ms/step - loss: 0.0633 - accuracy: 0.9954 - precision: 0.9938 - recall: 0.9969 - val_loss: 0.0672 - val_accuracy: 0.9917 - val_precision: 0.9877 - val_recall: 0.9959\n",
            "Epoch 12/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.0602 - accuracy: 0.9969 - precision: 0.9979 - recall: 0.9959 - val_loss: 0.0654 - val_accuracy: 0.9917 - val_precision: 0.9877 - val_recall: 0.9959\n",
            "Epoch 13/19\n",
            "122/122 [==============================] - 36s 298ms/step - loss: 0.0652 - accuracy: 0.9943 - precision: 0.9928 - recall: 0.9959 - val_loss: 0.0649 - val_accuracy: 0.9917 - val_precision: 0.9877 - val_recall: 0.9959\n",
            "Epoch 14/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.0572 - accuracy: 0.9964 - precision: 0.9949 - recall: 0.9979 - val_loss: 0.0651 - val_accuracy: 0.9917 - val_precision: 0.9877 - val_recall: 0.9959\n",
            "Epoch 15/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.0564 - accuracy: 0.9948 - precision: 0.9918 - recall: 0.9979 - val_loss: 0.0624 - val_accuracy: 0.9938 - val_precision: 0.9918 - val_recall: 0.9959\n",
            "Epoch 16/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.0538 - accuracy: 0.9974 - precision: 0.9979 - recall: 0.9969 - val_loss: 0.0622 - val_accuracy: 0.9938 - val_precision: 0.9918 - val_recall: 0.9959\n",
            "Epoch 17/19\n",
            "122/122 [==============================] - 36s 295ms/step - loss: 0.0537 - accuracy: 0.9974 - precision: 0.9979 - recall: 0.9969 - val_loss: 0.0620 - val_accuracy: 0.9938 - val_precision: 0.9918 - val_recall: 0.9959\n",
            "Epoch 18/19\n",
            "122/122 [==============================] - 38s 311ms/step - loss: 0.0535 - accuracy: 0.9974 - precision: 0.9969 - recall: 0.9979 - val_loss: 0.0616 - val_accuracy: 0.9938 - val_precision: 0.9918 - val_recall: 0.9959\n",
            "Epoch 19/19\n",
            "122/122 [==============================] - 36s 297ms/step - loss: 0.0560 - accuracy: 0.9959 - precision: 0.9969 - recall: 0.9948 - val_loss: 0.0625 - val_accuracy: 0.9938 - val_precision: 0.9918 - val_recall: 0.9959\n",
            "\n",
            "Accuracy: 99.38%\n",
            "\n",
            "learning rate: 9.5e-05\n",
            "num_dense_layers: 5\n",
            "num_dense_nodes: 422\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/19\n",
            "122/122 [==============================] - 41s 302ms/step - loss: 0.0682 - accuracy: 0.9928 - precision: 0.9893 - recall: 0.9967 - val_loss: 0.0706 - val_accuracy: 0.9917 - val_precision: 0.9837 - val_recall: 1.0000\n",
            "Epoch 2/19\n",
            "122/122 [==============================] - 36s 297ms/step - loss: 0.0474 - accuracy: 0.9990 - precision: 0.9990 - recall: 0.9990 - val_loss: 0.0837 - val_accuracy: 0.9917 - val_precision: 0.9837 - val_recall: 1.0000\n",
            "Epoch 3/19\n",
            "122/122 [==============================] - 37s 299ms/step - loss: 0.0613 - accuracy: 0.9938 - precision: 0.9928 - recall: 0.9948 - val_loss: 0.0675 - val_accuracy: 0.9917 - val_precision: 0.9958 - val_recall: 0.9876\n",
            "Epoch 4/19\n",
            "122/122 [==============================] - 36s 297ms/step - loss: 0.0501 - accuracy: 0.9979 - precision: 0.9990 - recall: 0.9969 - val_loss: 0.0610 - val_accuracy: 0.9959 - val_precision: 0.9959 - val_recall: 0.9959\n",
            "Epoch 5/19\n",
            "122/122 [==============================] - 36s 298ms/step - loss: 0.0502 - accuracy: 0.9959 - precision: 0.9979 - recall: 0.9938 - val_loss: 0.0603 - val_accuracy: 0.9959 - val_precision: 0.9959 - val_recall: 0.9959\n",
            "Epoch 6/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.0444 - accuracy: 0.9985 - precision: 0.9990 - recall: 0.9979 - val_loss: 0.0613 - val_accuracy: 0.9959 - val_precision: 0.9959 - val_recall: 0.9959\n",
            "Epoch 7/19\n",
            "122/122 [==============================] - 38s 310ms/step - loss: 0.0443 - accuracy: 0.9985 - precision: 0.9990 - recall: 0.9979 - val_loss: 0.0650 - val_accuracy: 0.9938 - val_precision: 0.9959 - val_recall: 0.9917\n",
            "Epoch 8/19\n",
            "122/122 [==============================] - 39s 316ms/step - loss: 0.0578 - accuracy: 0.9964 - precision: 0.9969 - recall: 0.9959 - val_loss: 0.0509 - val_accuracy: 0.9959 - val_precision: 0.9959 - val_recall: 0.9959\n",
            "Epoch 9/19\n",
            "122/122 [==============================] - 36s 297ms/step - loss: 0.0453 - accuracy: 0.9990 - precision: 1.0000 - recall: 0.9979 - val_loss: 0.0580 - val_accuracy: 0.9959 - val_precision: 0.9959 - val_recall: 0.9959\n",
            "Epoch 10/19\n",
            "122/122 [==============================] - 36s 298ms/step - loss: 0.0530 - accuracy: 0.9974 - precision: 0.9979 - recall: 0.9969 - val_loss: 0.0559 - val_accuracy: 0.9959 - val_precision: 0.9959 - val_recall: 0.9959\n",
            "Epoch 11/19\n",
            "122/122 [==============================] - 36s 295ms/step - loss: 0.0461 - accuracy: 0.9979 - precision: 0.9979 - recall: 0.9979 - val_loss: 0.0539 - val_accuracy: 0.9959 - val_precision: 0.9959 - val_recall: 0.9959\n",
            "Epoch 12/19\n",
            "122/122 [==============================] - 36s 297ms/step - loss: 0.0438 - accuracy: 0.9990 - precision: 0.9990 - recall: 0.9990 - val_loss: 0.0529 - val_accuracy: 0.9959 - val_precision: 0.9959 - val_recall: 0.9959\n",
            "Epoch 13/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.0580 - accuracy: 0.9995 - precision: 1.0000 - recall: 0.9990 - val_loss: 0.0678 - val_accuracy: 0.9938 - val_precision: 0.9918 - val_recall: 0.9959\n",
            "Epoch 14/19\n",
            "122/122 [==============================] - 36s 297ms/step - loss: 0.0474 - accuracy: 0.9974 - precision: 0.9979 - recall: 0.9969 - val_loss: 0.0643 - val_accuracy: 0.9959 - val_precision: 0.9959 - val_recall: 0.9959\n",
            "Epoch 15/19\n",
            "122/122 [==============================] - 38s 307ms/step - loss: 0.0453 - accuracy: 0.9974 - precision: 0.9990 - recall: 0.9959 - val_loss: 0.0600 - val_accuracy: 0.9959 - val_precision: 0.9959 - val_recall: 0.9959\n",
            "Epoch 16/19\n",
            "122/122 [==============================] - 37s 301ms/step - loss: 0.0443 - accuracy: 0.9985 - precision: 0.9990 - recall: 0.9979 - val_loss: 0.0585 - val_accuracy: 0.9959 - val_precision: 0.9959 - val_recall: 0.9959\n",
            "Epoch 17/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.0420 - accuracy: 0.9995 - precision: 1.0000 - recall: 0.9990 - val_loss: 0.0576 - val_accuracy: 0.9959 - val_precision: 0.9959 - val_recall: 0.9959\n",
            "Epoch 18/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.0449 - accuracy: 0.9974 - precision: 0.9979 - recall: 0.9969 - val_loss: 0.0640 - val_accuracy: 0.9938 - val_precision: 0.9918 - val_recall: 0.9959\n",
            "Epoch 19/19\n",
            "122/122 [==============================] - 36s 296ms/step - loss: 0.0708 - accuracy: 0.9974 - precision: 1.0000 - recall: 0.9948 - val_loss: 0.1473 - val_accuracy: 0.9855 - val_precision: 0.9757 - val_recall: 0.9959\n",
            "\n",
            "Accuracy: 98.55%\n",
            "\n",
            "learning rate: 6.8e-06\n",
            "num_dense_layers: 1\n",
            "num_dense_nodes: 512\n",
            "activation: relu\n",
            "\n",
            "Epoch 1/19\n",
            " 71/122 [================>.............] - ETA: 13s - loss: 0.1662 - accuracy: 0.9724 - precision: 0.9564 - recall: 0.9975"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-aeb6a3dcce28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"search_result = gp_minimize(func=fitness,\\n                            dimensions=dimensions,\\n                            acq_func='EI', # Expected Improvement.\\n                            n_calls=50,\\n                            x0=default_parameters)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skopt/optimizer/gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         callback=callback, n_jobs=n_jobs, model_queue_size=model_queue_size)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_calls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0mnext_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skopt/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0;31m# Call the wrapped objective function with the named arguments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mobjective_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0marg_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobjective_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-9da6db7b8ada>\u001b[0m in \u001b[0;36mfitness\u001b[0;34m(learning_rate, num_dense_layers, num_dense_nodes, activation)\u001b[0m\n\u001b[1;32m     47\u001b[0m                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_steps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                         callbacks=[callback_log])\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1387\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \"\"\"\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m       \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m     \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \"\"\"\n\u001b[1;32m   1222\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1187\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chO3WaWc86SR"
      },
      "outputs": [],
      "source": [
        "load_saved_model = ('/content/drive/MyDrive/Liveness/Model/FaceM3.h5')\n",
        "live_model = tf.keras.models.load_model(str(load_saved_model), \n",
        "                                         custom_objects = {'KerasLayer':hub.KerasLayer})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGRC0ImiKcV8",
        "outputId": "0f8a05e1-e82f-409e-dfab-baf9d5f308c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31/31 [==============================] - 4s 92ms/step - loss: 0.0595 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
            "Final loss: 0.06\n",
            "Final accuracy: 100.00%\n",
            "Precision: 100.00%\n",
            "Recall: 100.00%\n",
            "F1-score: 100.00%\n"
          ]
        }
      ],
      "source": [
        "final_loss, final_accuracy, precision, recall = live_model.evaluate(valid_generator, steps = val_steps_per_epoch)\n",
        "print(\"Final loss: {:.2f}\".format(final_loss))\n",
        "print(\"Final accuracy: {:.2f}%\".format(final_accuracy * 100))\n",
        "print(\"Precision: {:.2f}%\".format(precision * 100))\n",
        "print(\"Recall: {:.2f}%\".format(recall* 100))\n",
        "print(\"F1-score: {:.2f}%\".format((2*(precision*recall)/(precision+recall))* 100))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "FaceM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}