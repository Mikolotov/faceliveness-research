{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "UyXDkcv3Ircx"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import copy2\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "qm7JO3w-JHW-"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "  # The %tensorflow_version magic only works in colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "hadEMy5WJKgz"
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "5VLdTiAhJNDY",
    "outputId": "0af4a448-a52b-4c9e-d940-ef2dc31aa389"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.1'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "vlDCxuIaICFV"
   },
   "outputs": [],
   "source": [
    "data_root = ('dataset4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "19zEBB7YIWrJ"
   },
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (224, 224) # (height, width) in no. of pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "JHY7V3BEIZJA"
   },
   "outputs": [],
   "source": [
    "TRAINING_DATA_DIR = str(data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "sro8H-E-IaqO"
   },
   "outputs": [],
   "source": [
    "datagen_kwargs = dict(rescale=1./255, validation_split=.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LCP07qx_IdVR",
    "outputId": "5d5de883-f63e-4904-a3b7-7c88789e0b66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5112 images belonging to 2 classes.\n",
      "Found 3409 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs)\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "TRAINING_DATA_DIR,\n",
    "subset='validation',\n",
    "batch_size=16,\n",
    "shuffle=True,\n",
    "seed=123,\n",
    "class_mode='binary', # categorical or binary\n",
    "target_size=IMAGE_SHAPE\n",
    ")\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs,\n",
    "                                                                rotation_range=15, \n",
    "                                                                zoom_range=0.1,\n",
    "\t                                                              width_shift_range=0.15, \n",
    "                                                                height_shift_range=0.15, \n",
    "                                                                shear_range=0.1,\n",
    "                                                                fill_mode=\"nearest\",\n",
    "                                                                horizontal_flip=True\n",
    "                                                                )\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "TRAINING_DATA_DIR,\n",
    "subset='training',\n",
    "batch_size=16,\n",
    "shuffle=True,\n",
    "seed=123,\n",
    "class_mode='binary', # categorical or binary\n",
    "target_size=IMAGE_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wyu947ofIixy",
    "outputId": "370723ad-46fb-49f1-eb45-d17be7b91b96"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16, 224, 224, 3), (16,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "for image_batch, label_batch in train_generator:\n",
    "  break\n",
    "image_batch.shape, label_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "76-LxHNQJibp",
    "outputId": "8d4340f5-c2ad-445a-b872-bdedccc8af6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Real': 0, 'Spoof': 1}\n"
     ]
    }
   ],
   "source": [
    "print (train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "OsA25JGvJ20G"
   },
   "outputs": [],
   "source": [
    "labels = '\\n'.join(sorted(train_generator.class_indices.keys()))\n",
    "\n",
    "with open('labels.txt', 'w') as f:\n",
    "  f.write(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eytoeJfQJ8Vq",
    "outputId": "c48a30a1-6a8b-4ed2-af20-1baf9ae1f69f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real\n",
      "Spoof\n"
     ]
    }
   ],
   "source": [
    "f = open('labels.txt')\n",
    "print(f.read()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "G6iDzLxWJ-ny"
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "V2PxIjzYLsOi"
   },
   "outputs": [],
   "source": [
    "base_model = hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v2_075_224/classification/5\", \n",
    "                 trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "yNeu-AwTkA5D"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "vXBut8erlgrk"
   },
   "outputs": [],
   "source": [
    "import skopt\n",
    "from skopt import gp_minimize, forest_minimize\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.plots import plot_convergence\n",
    "from skopt.plots import plot_objective, plot_evaluations\n",
    "from skopt.plots import plot_histogram, plot_objective_2D\n",
    "from skopt.utils import use_named_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "5IZQ9sbqkNkX"
   },
   "outputs": [],
   "source": [
    "dim_learning_rate = Real(low=1e-6, high=1e-2, prior='log-uniform',\n",
    "                         name='learning_rate')\n",
    "\n",
    "dim_num_dense_layers = Integer(low=1, high=5, name='num_dense_layers')\n",
    "\n",
    "dim_num_dense_nodes = Integer(low=5, high=512, name='num_dense_nodes')\n",
    "\n",
    "dim_activation = Categorical(categories=['relu', 'sigmoid'],\n",
    "                             name='activation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "OPpal6bTkXur"
   },
   "outputs": [],
   "source": [
    "dimensions = [dim_learning_rate,\n",
    "              dim_num_dense_layers,\n",
    "              dim_num_dense_nodes,\n",
    "              dim_activation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "dmP43tqfkbdR"
   },
   "outputs": [],
   "source": [
    "default_parameters = [1e-5, 1, 16, 'relu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "jNRR5d5QsX_F"
   },
   "outputs": [],
   "source": [
    "#path_best_model = '/content/drive/MyDrive/Liveness/Model/best_model.h5'\n",
    "#local\n",
    "path_best_model = 'best_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "ZtASpNv6sZ4p"
   },
   "outputs": [],
   "source": [
    "best_accuracy = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "9ZEOLGAM32GP"
   },
   "outputs": [],
   "source": [
    "precision = tf.keras.metrics.Precision()\n",
    "recall = tf.keras.metrics.Recall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "JymlisTBEcnX"
   },
   "outputs": [],
   "source": [
    "steps_per_epoch = np.ceil(train_generator.samples/train_generator.batch_size)\n",
    "val_steps_per_epoch = np.ceil(valid_generator.samples/valid_generator.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "kSkCWjzVvhL4"
   },
   "outputs": [],
   "source": [
    "def log_dir_name(learning_rate, num_dense_layers,\n",
    "                 num_dense_nodes, activation):\n",
    "\n",
    "    # The dir-name for the TensorBoard log-dir.\n",
    "    s = \"./19_logs/lr_{0:.0e}_layers_{1}_nodes_{2}_{3}/\"\n",
    "\n",
    "    # Insert all the hyper-parameters in the dir-name.\n",
    "    log_dir = s.format(learning_rate,\n",
    "                       num_dense_layers,\n",
    "                       num_dense_nodes,\n",
    "                       activation)\n",
    "\n",
    "    return log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "WEw-1Mw7vGk6"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Input\n",
    "from tensorflow.keras.layers import Reshape, MaxPooling2D\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "9Ds0xOl8tbWM"
   },
   "outputs": [],
   "source": [
    "def create_model(learning_rate, num_dense_layers,\n",
    "                 num_dense_nodes, activation):\n",
    "    \"\"\"\n",
    "    Hyper-parameters:\n",
    "    learning_rate:     Learning-rate for the optimizer.\n",
    "    num_dense_layers:  Number of dense layers.\n",
    "    num_dense_nodes:   Number of nodes in each dense layer.\n",
    "    activation:        Activation function for all layers.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Start construction of a Keras Sequential model.\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add an input layer which is similar to a feed_dict in TensorFlow.\n",
    "    # Note that the input-shape must be a tuple containing the image-size.\n",
    "    model.add(base_model)\n",
    "\n",
    "    # Add fully-connected / dense layers.\n",
    "    # The number of layers is a hyper-parameter we want to optimize.\n",
    "    for i in range(num_dense_layers):\n",
    "        # Name of the layer. This is not really necessary\n",
    "        # because Keras should give them unique names.\n",
    "        name = 'layer_dense_{0}'.format(i+1)\n",
    "\n",
    "        # Add the dense / fully-connected layer to the model.\n",
    "        # This has two hyper-parameters we want to optimize:\n",
    "        # The number of nodes and the activation function.\n",
    "        model.add(Dense(num_dense_nodes,\n",
    "                        activation=activation,\n",
    "                        name=name))\n",
    "\n",
    "    # Last fully-connected / dense layer with softmax-activation\n",
    "    # for use in classification.\n",
    "    \n",
    "    model.add(Dense(train_generator.num_classes-1, activation='sigmoid'))\n",
    "    \n",
    "    # Use the Adam method for training the network.\n",
    "    # We want to find the best learning-rate for the Adam method.\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    # In Keras we need to compile the model so it can be trained.\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', precision, recall])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "DEnzyO49sRpB"
   },
   "outputs": [],
   "source": [
    "@use_named_args(dimensions=dimensions)\n",
    "\n",
    "def fitness(learning_rate, num_dense_layers,\n",
    "            num_dense_nodes, activation):\n",
    "    \"\"\"\n",
    "    Hyper-parameters:\n",
    "    learning_rate:     Learning-rate for the optimizer.\n",
    "    num_dense_layers:  Number of dense layers.\n",
    "    num_dense_nodes:   Number of nodes in each dense layer.\n",
    "    activation:        Activation function for all layers.\n",
    "    \"\"\"\n",
    "\n",
    "    # Print the hyper-parameters.\n",
    "    print('learning rate: {0:.1e}'.format(learning_rate))\n",
    "    print('num_dense_layers:', num_dense_layers)\n",
    "    print('num_dense_nodes:', num_dense_nodes)\n",
    "    print('activation:', activation)\n",
    "    print()\n",
    "    \n",
    "    # Create the neural network with these hyper-parameters.\n",
    "    model = create_model(learning_rate=learning_rate,\n",
    "                         num_dense_layers=num_dense_layers,\n",
    "                         num_dense_nodes=num_dense_nodes,\n",
    "                         activation=activation)\n",
    "\n",
    "    # Dir-name for the TensorBoard log-files.\n",
    "    log_dir = log_dir_name(learning_rate, num_dense_layers,\n",
    "                           num_dense_nodes, activation)\n",
    "    \n",
    "    # Create a callback-function for Keras which will be\n",
    "    # run after each epoch has ended during training.\n",
    "    # This saves the log-files for TensorBoard.\n",
    "    # Note that there are complications when histogram_freq=1.\n",
    "    # It might give strange errors and it also does not properly\n",
    "    # support Keras data-generators for the validation-set.\n",
    "    callback_log = TensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        histogram_freq=0,\n",
    "        write_graph=True,\n",
    "        write_grads=False,\n",
    "        write_images=False)\n",
    "   \n",
    "    # Use Keras to train the model.\n",
    "    history = model.fit(train_generator,\n",
    "                        epochs=19,\n",
    "                        validation_data=valid_generator,\n",
    "                        steps_per_epoch=steps_per_epoch,\n",
    "                        validation_steps=val_steps_per_epoch,\n",
    "                        callbacks=[callback_log])\n",
    "    \n",
    "\n",
    "\n",
    "    # Get the classification accuracy on the validation-set\n",
    "    # after the last training-epoch.\n",
    "    accuracy = history.history['val_accuracy'][-1]\n",
    "\n",
    "    # Print the classification accuracy.\n",
    "    print()\n",
    "    print(\"Accuracy: {0:.2%}\".format(accuracy))\n",
    "    print()\n",
    "\n",
    "    # Save the model if it improves on the best-found performance.\n",
    "    # We use the global keyword so we update the variable outside\n",
    "    # of this function.\n",
    "    global best_accuracy\n",
    "\n",
    "    # If the classification accuracy of the saved model is improved ...\n",
    "    if accuracy > best_accuracy:\n",
    "        # Save the new model to harddisk.\n",
    "        model.save(path_best_model)\n",
    "        \n",
    "        # Update the classification accuracy.\n",
    "        best_accuracy = accuracy\n",
    "\n",
    "    # Delete the Keras model with these hyper-parameters from memory.\n",
    "    del model\n",
    "    \n",
    "    # Clear the Keras session, otherwise it will keep adding new\n",
    "    # models to the same TensorFlow graph each time we create\n",
    "    # a model with a different set of hyper-parameters.\n",
    "    K.clear_session()\n",
    "    \n",
    "    # NOTE: Scikit-optimize does minimization so it tries to\n",
    "    # find a set of hyper-parameters with the LOWEST fitness-value.\n",
    "    # Because we are interested in the HIGHEST classification\n",
    "    # accuracy, we need to negate this number so it can be minimized.\n",
    "    return -accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pop1Kye3s_V_",
    "outputId": "66da8cbe-b642-496a-beba-046012fd61d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 1.0e-05\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 16\n",
      "activation: relu\n",
      "\n",
      "Epoch 1/19\n",
      "122/122 [==============================] - 35s 225ms/step - loss: 0.7412 - accuracy: 0.6677 - precision: 0.6670 - recall: 0.6684 - val_loss: 0.6200 - val_accuracy: 0.7479 - val_precision: 0.8371 - val_recall: 0.6157\n",
      "Epoch 2/19\n",
      "122/122 [==============================] - 19s 157ms/step - loss: 0.5360 - accuracy: 0.8065 - precision: 0.8105 - recall: 0.7996 - val_loss: 0.4203 - val_accuracy: 0.8595 - val_precision: 0.8425 - val_recall: 0.8843\n",
      "Epoch 3/19\n",
      "122/122 [==============================] - 18s 149ms/step - loss: 0.4315 - accuracy: 0.8658 - precision: 0.8642 - recall: 0.8678 - val_loss: 0.3396 - val_accuracy: 0.9091 - val_precision: 0.8667 - val_recall: 0.9669\n",
      "Epoch 4/19\n",
      "122/122 [==============================] - 19s 151ms/step - loss: 0.3748 - accuracy: 0.8906 - precision: 0.8962 - recall: 0.8833 - val_loss: 0.3286 - val_accuracy: 0.9008 - val_precision: 0.8440 - val_recall: 0.9835\n",
      "Epoch 5/19\n",
      "122/122 [==============================] - 19s 159ms/step - loss: 0.3493 - accuracy: 0.9045 - precision: 0.8951 - recall: 0.9163 - val_loss: 0.2882 - val_accuracy: 0.9401 - val_precision: 0.9049 - val_recall: 0.9835\n",
      "Epoch 6/19\n",
      "122/122 [==============================] - 18s 151ms/step - loss: 0.2957 - accuracy: 0.9376 - precision: 0.9335 - recall: 0.9421 - val_loss: 0.2679 - val_accuracy: 0.9504 - val_precision: 0.9258 - val_recall: 0.9793\n",
      "Epoch 7/19\n",
      "122/122 [==============================] - 18s 151ms/step - loss: 0.2804 - accuracy: 0.9345 - precision: 0.9278 - recall: 0.9421 - val_loss: 0.2381 - val_accuracy: 0.9587 - val_precision: 0.9405 - val_recall: 0.9793\n",
      "Epoch 8/19\n",
      "122/122 [==============================] - 20s 160ms/step - loss: 0.2643 - accuracy: 0.9396 - precision: 0.9355 - recall: 0.9442 - val_loss: 0.2134 - val_accuracy: 0.9711 - val_precision: 0.9597 - val_recall: 0.9835\n",
      "Epoch 9/19\n",
      "122/122 [==============================] - 18s 151ms/step - loss: 0.2543 - accuracy: 0.9443 - precision: 0.9379 - recall: 0.9514 - val_loss: 0.2155 - val_accuracy: 0.9690 - val_precision: 0.9451 - val_recall: 0.9959\n",
      "Epoch 10/19\n",
      "122/122 [==============================] - 18s 148ms/step - loss: 0.2513 - accuracy: 0.9407 - precision: 0.9383 - recall: 0.9432 - val_loss: 0.2075 - val_accuracy: 0.9731 - val_precision: 0.9526 - val_recall: 0.9959\n",
      "Epoch 11/19\n",
      "122/122 [==============================] - 19s 156ms/step - loss: 0.2379 - accuracy: 0.9541 - precision: 0.9545 - recall: 0.9535 - val_loss: 0.1845 - val_accuracy: 0.9814 - val_precision: 0.9755 - val_recall: 0.9876\n",
      "Epoch 12/19\n",
      "122/122 [==============================] - 18s 149ms/step - loss: 0.2206 - accuracy: 0.9592 - precision: 0.9550 - recall: 0.9638 - val_loss: 0.1828 - val_accuracy: 0.9814 - val_precision: 0.9755 - val_recall: 0.9876\n",
      "Epoch 13/19\n",
      "122/122 [==============================] - 18s 148ms/step - loss: 0.2034 - accuracy: 0.9690 - precision: 0.9661 - recall: 0.9721 - val_loss: 0.1817 - val_accuracy: 0.9855 - val_precision: 0.9757 - val_recall: 0.9959\n",
      "Epoch 14/19\n",
      "122/122 [==============================] - 19s 153ms/step - loss: 0.1912 - accuracy: 0.9706 - precision: 0.9691 - recall: 0.9721 - val_loss: 0.1578 - val_accuracy: 0.9897 - val_precision: 0.9837 - val_recall: 0.9959\n",
      "Epoch 15/19\n",
      "122/122 [==============================] - 18s 147ms/step - loss: 0.2008 - accuracy: 0.9659 - precision: 0.9708 - recall: 0.9607 - val_loss: 0.1669 - val_accuracy: 0.9876 - val_precision: 0.9797 - val_recall: 0.9959\n",
      "Epoch 16/19\n",
      "122/122 [==============================] - 18s 148ms/step - loss: 0.2028 - accuracy: 0.9670 - precision: 0.9660 - recall: 0.9680 - val_loss: 0.1546 - val_accuracy: 0.9917 - val_precision: 0.9837 - val_recall: 1.0000\n",
      "Epoch 17/19\n",
      "122/122 [==============================] - 18s 149ms/step - loss: 0.1991 - accuracy: 0.9670 - precision: 0.9641 - recall: 0.9700 - val_loss: 0.1476 - val_accuracy: 0.9917 - val_precision: 0.9877 - val_recall: 0.9959\n",
      "Epoch 18/19\n",
      "122/122 [==============================] - 18s 148ms/step - loss: 0.1793 - accuracy: 0.9727 - precision: 0.9712 - recall: 0.9742 - val_loss: 0.1503 - val_accuracy: 0.9917 - val_precision: 0.9877 - val_recall: 0.9959\n",
      "Epoch 19/19\n",
      "122/122 [==============================] - 18s 148ms/step - loss: 0.1786 - accuracy: 0.9763 - precision: 0.9772 - recall: 0.9752 - val_loss: 0.1554 - val_accuracy: 0.9897 - val_precision: 0.9798 - val_recall: 1.0000\n",
      "\n",
      "Accuracy: 98.97%\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.9896694421768188"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitness(x=default_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "mmcQcv3DwDKj",
    "outputId": "7075d12a-108f-41a1-b8e5-bd570874e476"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 1.0e-05\n",
      "num_dense_layers: 1\n",
      "num_dense_nodes: 16\n",
      "activation: relu\n",
      "\n",
      "Epoch 1/19\n",
      "122/122 [==============================] - 23s 158ms/step - loss: 0.5200 - accuracy: 0.8050 - precision: 0.8376 - recall: 0.8479 - val_loss: 0.2858 - val_accuracy: 0.9483 - val_precision: 0.9157 - val_recall: 0.9876\n",
      "Epoch 2/19\n",
      "122/122 [==============================] - 19s 152ms/step - loss: 0.2870 - accuracy: 0.9345 - precision: 0.9304 - recall: 0.9390 - val_loss: 0.2182 - val_accuracy: 0.9669 - val_precision: 0.9414 - val_recall: 0.9959\n",
      "Epoch 3/19\n",
      "122/122 [==============================] - 18s 150ms/step - loss: 0.2305 - accuracy: 0.9541 - precision: 0.9536 - recall: 0.9545 - val_loss: 0.1947 - val_accuracy: 0.9752 - val_precision: 0.9528 - val_recall: 1.0000\n",
      "Epoch 4/19\n",
      "122/122 [==============================] - 18s 151ms/step - loss: 0.1924 - accuracy: 0.9685 - precision: 0.9604 - recall: 0.9773 - val_loss: 0.1829 - val_accuracy: 0.9773 - val_precision: 0.9565 - val_recall: 1.0000\n",
      "Epoch 5/19\n",
      "122/122 [==============================] - 19s 155ms/step - loss: 0.1804 - accuracy: 0.9742 - precision: 0.9761 - recall: 0.9721 - val_loss: 0.1769 - val_accuracy: 0.9752 - val_precision: 0.9563 - val_recall: 0.9959\n",
      "Epoch 6/19\n",
      "122/122 [==============================] - 18s 148ms/step - loss: 0.1771 - accuracy: 0.9794 - precision: 0.9706 - recall: 0.9886 - val_loss: 0.1722 - val_accuracy: 0.9814 - val_precision: 0.9755 - val_recall: 0.9876\n",
      "Epoch 7/19\n",
      "122/122 [==============================] - 19s 153ms/step - loss: 0.1752 - accuracy: 0.9768 - precision: 0.9733 - recall: 0.9804 - val_loss: 0.1588 - val_accuracy: 0.9855 - val_precision: 0.9757 - val_recall: 0.9959\n",
      "Epoch 8/19\n",
      "122/122 [==============================] - 19s 159ms/step - loss: 0.1703 - accuracy: 0.9804 - precision: 0.9784 - recall: 0.9824 - val_loss: 0.1510 - val_accuracy: 0.9876 - val_precision: 0.9797 - val_recall: 0.9959\n",
      "Epoch 9/19\n",
      "122/122 [==============================] - 18s 149ms/step - loss: 0.1844 - accuracy: 0.9768 - precision: 0.9832 - recall: 0.9700 - val_loss: 0.1483 - val_accuracy: 0.9897 - val_precision: 0.9837 - val_recall: 0.9959\n",
      "Epoch 10/19\n",
      "122/122 [==============================] - 18s 148ms/step - loss: 0.1745 - accuracy: 0.9752 - precision: 0.9723 - recall: 0.9783 - val_loss: 0.1467 - val_accuracy: 0.9897 - val_precision: 0.9798 - val_recall: 1.0000\n",
      "Epoch 11/19\n",
      "122/122 [==============================] - 18s 148ms/step - loss: 0.1498 - accuracy: 0.9892 - precision: 0.9886 - recall: 0.9897 - val_loss: 0.1483 - val_accuracy: 0.9876 - val_precision: 0.9797 - val_recall: 0.9959\n",
      "Epoch 12/19\n",
      "122/122 [==============================] - 18s 146ms/step - loss: 0.1448 - accuracy: 0.9907 - precision: 0.9877 - recall: 0.9938 - val_loss: 0.1395 - val_accuracy: 0.9897 - val_precision: 0.9837 - val_recall: 0.9959\n",
      "Epoch 13/19\n",
      "122/122 [==============================] - 18s 147ms/step - loss: 0.1532 - accuracy: 0.9850 - precision: 0.9825 - recall: 0.9876 - val_loss: 0.1375 - val_accuracy: 0.9897 - val_precision: 0.9837 - val_recall: 0.9959\n",
      "Epoch 14/19\n",
      "122/122 [==============================] - 18s 147ms/step - loss: 0.1631 - accuracy: 0.9804 - precision: 0.9824 - recall: 0.9783 - val_loss: 0.1528 - val_accuracy: 0.9876 - val_precision: 0.9758 - val_recall: 1.0000\n",
      "Epoch 15/19\n",
      "122/122 [==============================] - 19s 152ms/step - loss: 0.1529 - accuracy: 0.9856 - precision: 0.9865 - recall: 0.9845 - val_loss: 0.1397 - val_accuracy: 0.9876 - val_precision: 0.9758 - val_recall: 1.0000\n",
      "Epoch 16/19\n",
      "122/122 [==============================] - 18s 148ms/step - loss: 0.1463 - accuracy: 0.9861 - precision: 0.9866 - recall: 0.9855 - val_loss: 0.1447 - val_accuracy: 0.9897 - val_precision: 0.9798 - val_recall: 1.0000\n",
      "Epoch 17/19\n",
      "122/122 [==============================] - 18s 146ms/step - loss: 0.1581 - accuracy: 0.9845 - precision: 0.9865 - recall: 0.9824 - val_loss: 0.1321 - val_accuracy: 0.9917 - val_precision: 0.9877 - val_recall: 0.9959\n",
      "Epoch 18/19\n",
      "122/122 [==============================] - 19s 151ms/step - loss: 0.1531 - accuracy: 0.9876 - precision: 0.9836 - recall: 0.9917 - val_loss: 0.1390 - val_accuracy: 0.9917 - val_precision: 0.9877 - val_recall: 0.9959\n",
      "Epoch 19/19\n",
      "122/122 [==============================] - 18s 149ms/step - loss: 0.1406 - accuracy: 0.9892 - precision: 0.9917 - recall: 0.9866 - val_loss: 0.1353 - val_accuracy: 0.9917 - val_precision: 0.9877 - val_recall: 0.9959\n",
      "\n",
      "Accuracy: 99.17%\n",
      "\n",
      "learning rate: 1.1e-04\n",
      "num_dense_layers: 5\n",
      "num_dense_nodes: 496\n",
      "activation: relu\n",
      "\n",
      "Epoch 1/19\n",
      "122/122 [==============================] - 22s 153ms/step - loss: 0.2451 - accuracy: 0.9556 - precision: 0.9643 - recall: 0.9612 - val_loss: 0.1632 - val_accuracy: 0.9897 - val_precision: 0.9837 - val_recall: 0.9959\n",
      "Epoch 2/19\n",
      "122/122 [==============================] - 18s 148ms/step - loss: 0.1908 - accuracy: 0.9773 - precision: 0.9753 - recall: 0.9793 - val_loss: 0.1564 - val_accuracy: 0.9876 - val_precision: 0.9758 - val_recall: 1.0000\n",
      "Epoch 3/19\n",
      "122/122 [==============================] - 18s 150ms/step - loss: 0.1569 - accuracy: 0.9856 - precision: 0.9845 - recall: 0.9866 - val_loss: 0.1499 - val_accuracy: 0.9897 - val_precision: 0.9798 - val_recall: 1.0000\n",
      "Epoch 4/19\n",
      "122/122 [==============================] - 18s 150ms/step - loss: 0.1622 - accuracy: 0.9825 - precision: 0.9805 - recall: 0.9845 - val_loss: 0.1407 - val_accuracy: 0.9938 - val_precision: 0.9918 - val_recall: 0.9959\n",
      "Epoch 5/19\n",
      "122/122 [==============================] - 19s 151ms/step - loss: 0.1509 - accuracy: 0.9876 - precision: 0.9896 - recall: 0.9855 - val_loss: 0.1346 - val_accuracy: 0.9938 - val_precision: 0.9878 - val_recall: 1.0000\n",
      "Epoch 6/19\n",
      "122/122 [==============================] - 18s 150ms/step - loss: 0.1396 - accuracy: 0.9902 - precision: 0.9897 - recall: 0.9907 - val_loss: 0.1307 - val_accuracy: 0.9938 - val_precision: 0.9878 - val_recall: 1.0000\n",
      "Epoch 7/19\n",
      "122/122 [==============================] - 18s 150ms/step - loss: 0.1840 - accuracy: 0.9742 - precision: 0.9781 - recall: 0.9700 - val_loss: 0.1870 - val_accuracy: 0.9855 - val_precision: 0.9719 - val_recall: 1.0000\n",
      "Epoch 8/19\n",
      "122/122 [==============================] - 18s 147ms/step - loss: 0.1698 - accuracy: 0.9788 - precision: 0.9793 - recall: 0.9783 - val_loss: 0.1291 - val_accuracy: 0.9938 - val_precision: 0.9959 - val_recall: 0.9917\n",
      "Epoch 9/19\n",
      "122/122 [==============================] - 18s 149ms/step - loss: 0.1463 - accuracy: 0.9840 - precision: 0.9865 - recall: 0.9814 - val_loss: 0.1271 - val_accuracy: 0.9959 - val_precision: 1.0000 - val_recall: 0.9917\n",
      "Epoch 10/19\n",
      "122/122 [==============================] - 18s 147ms/step - loss: 0.1315 - accuracy: 0.9933 - precision: 0.9938 - recall: 0.9928 - val_loss: 0.1601 - val_accuracy: 0.9814 - val_precision: 0.9641 - val_recall: 1.0000\n",
      "Epoch 11/19\n",
      "122/122 [==============================] - 18s 147ms/step - loss: 0.1328 - accuracy: 0.9928 - precision: 0.9938 - recall: 0.9917 - val_loss: 0.1213 - val_accuracy: 0.9938 - val_precision: 0.9878 - val_recall: 1.0000\n",
      "Epoch 12/19\n",
      "122/122 [==============================] - 18s 149ms/step - loss: 0.1567 - accuracy: 0.9840 - precision: 0.9835 - recall: 0.9845 - val_loss: 0.1175 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 13/19\n",
      "122/122 [==============================] - 18s 147ms/step - loss: 0.1579 - accuracy: 0.9845 - precision: 0.9855 - recall: 0.9835 - val_loss: 0.1886 - val_accuracy: 0.9814 - val_precision: 0.9874 - val_recall: 0.9752\n",
      "Epoch 14/19\n",
      "122/122 [==============================] - 18s 147ms/step - loss: 0.1605 - accuracy: 0.9825 - precision: 0.9795 - recall: 0.9855 - val_loss: 0.1167 - val_accuracy: 0.9979 - val_precision: 1.0000 - val_recall: 0.9959\n",
      "Epoch 15/19\n",
      "122/122 [==============================] - 18s 149ms/step - loss: 0.1229 - accuracy: 0.9959 - precision: 0.9969 - recall: 0.9948 - val_loss: 0.1121 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 16/19\n",
      "122/122 [==============================] - 18s 147ms/step - loss: 0.1431 - accuracy: 0.9907 - precision: 0.9917 - recall: 0.9897 - val_loss: 0.2294 - val_accuracy: 0.9669 - val_precision: 0.9380 - val_recall: 1.0000\n",
      "Epoch 17/19\n",
      "122/122 [==============================] - 18s 147ms/step - loss: 0.1230 - accuracy: 0.9954 - precision: 0.9928 - recall: 0.9979 - val_loss: 0.1319 - val_accuracy: 0.9959 - val_precision: 0.9918 - val_recall: 1.0000\n",
      "Epoch 18/19\n",
      "122/122 [==============================] - 18s 149ms/step - loss: 0.1247 - accuracy: 0.9969 - precision: 0.9969 - recall: 0.9969 - val_loss: 0.1148 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 19/19\n",
      "122/122 [==============================] - 18s 148ms/step - loss: 0.1228 - accuracy: 0.9969 - precision: 0.9959 - recall: 0.9979 - val_loss: 0.2380 - val_accuracy: 0.9525 - val_precision: 0.9824 - val_recall: 0.9215\n",
      "\n",
      "Accuracy: 95.25%\n",
      "\n",
      "learning rate: 2.2e-03\n",
      "num_dense_layers: 3\n",
      "num_dense_nodes: 495\n",
      "activation: relu\n",
      "\n",
      "Epoch 1/19\n",
      "122/122 [==============================] - 23s 154ms/step - loss: 0.7121 - accuracy: 0.7833 - precision: 0.8225 - recall: 0.8083 - val_loss: 1.0243 - val_accuracy: 0.5124 - val_precision: 0.8750 - val_recall: 0.0289\n",
      "Epoch 2/19\n",
      "122/122 [==============================] - 21s 172ms/step - loss: 0.3665 - accuracy: 0.9138 - precision: 0.9033 - recall: 0.9267 - val_loss: 0.6291 - val_accuracy: 0.7955 - val_precision: 0.7109 - val_recall: 0.9959\n",
      "Epoch 3/19\n",
      "122/122 [==============================] - 20s 163ms/step - loss: 0.3613 - accuracy: 0.9087 - precision: 0.8975 - recall: 0.9225 - val_loss: 0.7441 - val_accuracy: 0.8285 - val_precision: 0.7477 - val_recall: 0.9917\n",
      "Epoch 4/19\n",
      "122/122 [==============================] - 19s 155ms/step - loss: 0.3652 - accuracy: 0.9174 - precision: 0.9089 - recall: 0.9277 - val_loss: 1.5079 - val_accuracy: 0.8802 - val_precision: 0.8333 - val_recall: 0.9504\n",
      "Epoch 5/19\n",
      "122/122 [==============================] - 19s 152ms/step - loss: 0.5637 - accuracy: 0.8586 - precision: 0.8637 - recall: 0.8512 - val_loss: 0.6732 - val_accuracy: 0.6736 - val_precision: 0.6071 - val_recall: 0.9835\n",
      "Epoch 6/19\n",
      "122/122 [==============================] - 19s 155ms/step - loss: 0.4750 - accuracy: 0.8602 - precision: 0.8903 - recall: 0.8213 - val_loss: 1.1660 - val_accuracy: 0.8574 - val_precision: 0.8419 - val_recall: 0.8802\n",
      "Epoch 7/19\n",
      "122/122 [==============================] - 18s 150ms/step - loss: 0.3455 - accuracy: 0.9278 - precision: 0.9376 - recall: 0.9163 - val_loss: 0.3944 - val_accuracy: 0.8967 - val_precision: 0.9248 - val_recall: 0.8636\n",
      "Epoch 8/19\n",
      "122/122 [==============================] - 18s 148ms/step - loss: 0.3601 - accuracy: 0.9247 - precision: 0.9290 - recall: 0.9194 - val_loss: 0.3766 - val_accuracy: 0.9463 - val_precision: 0.9779 - val_recall: 0.9132\n",
      "Epoch 9/19\n",
      "122/122 [==============================] - 19s 158ms/step - loss: 0.2329 - accuracy: 0.9551 - precision: 0.9613 - recall: 0.9483 - val_loss: 0.6126 - val_accuracy: 0.8079 - val_precision: 0.9869 - val_recall: 0.6240\n",
      "Epoch 10/19\n",
      "122/122 [==============================] - 18s 150ms/step - loss: 0.2247 - accuracy: 0.9510 - precision: 0.9668 - recall: 0.9339 - val_loss: 0.6160 - val_accuracy: 0.8905 - val_precision: 0.8412 - val_recall: 0.9628\n",
      "Epoch 11/19\n",
      "122/122 [==============================] - 18s 148ms/step - loss: 0.4077 - accuracy: 0.8638 - precision: 0.8359 - recall: 0.9050 - val_loss: 4.0513 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/19\n",
      "122/122 [==============================] - 19s 153ms/step - loss: 0.4756 - accuracy: 0.8509 - precision: 0.8338 - recall: 0.8760 - val_loss: 4.3120 - val_accuracy: 0.5599 - val_precision: 1.0000 - val_recall: 0.1198\n",
      "Epoch 13/19\n",
      "122/122 [==============================] - 19s 151ms/step - loss: 0.3818 - accuracy: 0.8963 - precision: 0.8941 - recall: 0.8988 - val_loss: 0.3679 - val_accuracy: 0.9174 - val_precision: 0.9764 - val_recall: 0.8554\n",
      "Epoch 14/19\n",
      "122/122 [==============================] - 18s 152ms/step - loss: 0.3324 - accuracy: 0.9128 - precision: 0.9175 - recall: 0.9070 - val_loss: 1.4900 - val_accuracy: 0.8244 - val_precision: 0.7445 - val_recall: 0.9876\n",
      "Epoch 15/19\n",
      "122/122 [==============================] - 19s 156ms/step - loss: 0.2809 - accuracy: 0.9417 - precision: 0.9533 - recall: 0.9287 - val_loss: 0.8080 - val_accuracy: 0.9298 - val_precision: 0.9160 - val_recall: 0.9463\n",
      "Epoch 16/19\n",
      "122/122 [==============================] - 18s 150ms/step - loss: 0.2606 - accuracy: 0.9422 - precision: 0.9341 - recall: 0.9514 - val_loss: 0.1779 - val_accuracy: 0.9711 - val_precision: 0.9711 - val_recall: 0.9711\n",
      "Epoch 17/19\n",
      "122/122 [==============================] - 18s 150ms/step - loss: 0.2916 - accuracy: 0.9247 - precision: 0.9143 - recall: 0.9370 - val_loss: 3.3875 - val_accuracy: 0.7913 - val_precision: 0.9930 - val_recall: 0.5868\n",
      "Epoch 18/19\n",
      "122/122 [==============================] - 19s 153ms/step - loss: 0.1968 - accuracy: 0.9598 - precision: 0.9578 - recall: 0.9618 - val_loss: 0.1525 - val_accuracy: 0.9731 - val_precision: 0.9598 - val_recall: 0.9876\n",
      "Epoch 19/19\n",
      "122/122 [==============================] - 18s 147ms/step - loss: 0.5265 - accuracy: 0.8173 - precision: 0.8016 - recall: 0.8430 - val_loss: 2.4492 - val_accuracy: 0.5227 - val_precision: 0.9231 - val_recall: 0.0496\n",
      "\n",
      "Accuracy: 52.27%\n",
      "\n",
      "learning rate: 1.1e-03\n",
      "num_dense_layers: 2\n",
      "num_dense_nodes: 227\n",
      "activation: sigmoid\n",
      "\n",
      "Epoch 1/19\n",
      "122/122 [==============================] - 23s 154ms/step - loss: 0.4071 - accuracy: 0.8860 - precision: 0.8883 - recall: 0.7165 - val_loss: 0.4142 - val_accuracy: 0.8926 - val_precision: 0.8369 - val_recall: 0.9752\n",
      "Epoch 2/19\n",
      "122/122 [==============================] - 18s 148ms/step - loss: 0.2690 - accuracy: 0.9319 - precision: 0.9283 - recall: 0.9360 - val_loss: 0.2653 - val_accuracy: 0.9421 - val_precision: 0.8993 - val_recall: 0.9959\n",
      "Epoch 3/19\n",
      "122/122 [==============================] - 18s 151ms/step - loss: 0.2738 - accuracy: 0.9257 - precision: 0.9196 - recall: 0.9329 - val_loss: 1.0365 - val_accuracy: 0.7727 - val_precision: 0.9853 - val_recall: 0.5537\n",
      "Epoch 4/19\n",
      "122/122 [==============================] - 19s 151ms/step - loss: 0.2461 - accuracy: 0.9319 - precision: 0.9292 - recall: 0.9349 - val_loss: 0.2356 - val_accuracy: 0.9380 - val_precision: 0.9015 - val_recall: 0.9835\n",
      "Epoch 5/19\n",
      "122/122 [==============================] - 18s 150ms/step - loss: 0.1981 - accuracy: 0.9546 - precision: 0.9427 - recall: 0.9680 - val_loss: 0.3518 - val_accuracy: 0.8967 - val_precision: 0.8288 - val_recall: 1.0000\n",
      "Epoch 6/19\n",
      "122/122 [==============================] - 19s 154ms/step - loss: 0.2053 - accuracy: 0.9499 - precision: 0.9476 - recall: 0.9525 - val_loss: 0.2042 - val_accuracy: 0.9504 - val_precision: 0.9098 - val_recall: 1.0000\n",
      "Epoch 7/19\n",
      "122/122 [==============================] - 18s 150ms/step - loss: 0.1985 - accuracy: 0.9561 - precision: 0.9575 - recall: 0.9545 - val_loss: 0.1639 - val_accuracy: 0.9731 - val_precision: 0.9562 - val_recall: 0.9917\n",
      "Epoch 8/19\n",
      "122/122 [==============================] - 18s 150ms/step - loss: 0.1545 - accuracy: 0.9685 - precision: 0.9719 - recall: 0.9649 - val_loss: 0.3673 - val_accuracy: 0.9174 - val_precision: 0.8582 - val_recall: 1.0000\n",
      "Epoch 9/19\n",
      "122/122 [==============================] - 19s 152ms/step - loss: 0.1343 - accuracy: 0.9747 - precision: 0.9812 - recall: 0.9680 - val_loss: 0.1281 - val_accuracy: 0.9855 - val_precision: 0.9796 - val_recall: 0.9917\n",
      "Epoch 10/19\n",
      "122/122 [==============================] - 18s 151ms/step - loss: 0.2268 - accuracy: 0.9427 - precision: 0.9333 - recall: 0.9535 - val_loss: 0.5530 - val_accuracy: 0.8161 - val_precision: 0.7398 - val_recall: 0.9752\n",
      "Epoch 11/19\n",
      "122/122 [==============================] - 18s 149ms/step - loss: 0.2691 - accuracy: 0.9185 - precision: 0.9042 - recall: 0.9360 - val_loss: 0.1603 - val_accuracy: 0.9752 - val_precision: 0.9563 - val_recall: 0.9959\n",
      "Epoch 12/19\n",
      "122/122 [==============================] - 21s 175ms/step - loss: 0.1838 - accuracy: 0.9551 - precision: 0.9499 - recall: 0.9607 - val_loss: 0.2605 - val_accuracy: 0.9483 - val_precision: 0.9064 - val_recall: 1.0000\n",
      "Epoch 13/19\n",
      "122/122 [==============================] - 25s 203ms/step - loss: 0.1415 - accuracy: 0.9685 - precision: 0.9759 - recall: 0.9607 - val_loss: 0.1426 - val_accuracy: 0.9649 - val_precision: 0.9747 - val_recall: 0.9545\n",
      "Epoch 14/19\n",
      "122/122 [==============================] - 22s 179ms/step - loss: 0.1445 - accuracy: 0.9737 - precision: 0.9751 - recall: 0.9721 - val_loss: 0.1370 - val_accuracy: 0.9731 - val_precision: 0.9791 - val_recall: 0.9669\n",
      "Epoch 15/19\n",
      "122/122 [==============================] - 27s 220ms/step - loss: 0.1556 - accuracy: 0.9742 - precision: 0.9771 - recall: 0.9711 - val_loss: 0.2692 - val_accuracy: 0.9318 - val_precision: 0.8885 - val_recall: 0.9876\n",
      "Epoch 16/19\n",
      "122/122 [==============================] - 24s 195ms/step - loss: 0.1390 - accuracy: 0.9742 - precision: 0.9752 - recall: 0.9731 - val_loss: 0.5353 - val_accuracy: 0.8264 - val_precision: 0.7453 - val_recall: 0.9917\n",
      "Epoch 17/19\n",
      "122/122 [==============================] - 29s 240ms/step - loss: 0.1211 - accuracy: 0.9788 - precision: 0.9754 - recall: 0.9824 - val_loss: 0.1144 - val_accuracy: 0.9835 - val_precision: 0.9680 - val_recall: 1.0000\n",
      "Epoch 18/19\n",
      "122/122 [==============================] - 31s 254ms/step - loss: 0.1010 - accuracy: 0.9845 - precision: 0.9835 - recall: 0.9855 - val_loss: 0.1608 - val_accuracy: 0.9628 - val_precision: 0.9308 - val_recall: 1.0000\n",
      "Epoch 19/19\n",
      "122/122 [==============================] - 31s 254ms/step - loss: 0.1111 - accuracy: 0.9814 - precision: 0.9794 - recall: 0.9835 - val_loss: 0.7279 - val_accuracy: 0.7810 - val_precision: 1.0000 - val_recall: 0.5620\n",
      "\n",
      "Accuracy: 78.10%\n",
      "\n",
      "learning rate: 2.0e-03\n",
      "num_dense_layers: 3\n",
      "num_dense_nodes: 320\n",
      "activation: relu\n",
      "\n",
      "Epoch 1/19\n",
      "122/122 [==============================] - 29s 203ms/step - loss: 0.4188 - accuracy: 0.9303 - precision: 0.9385 - recall: 0.8570 - val_loss: 81.8686 - val_accuracy: 0.6198 - val_precision: 1.0000 - val_recall: 0.2397\n",
      "Epoch 2/19\n",
      "122/122 [==============================] - 19s 155ms/step - loss: 0.5926 - accuracy: 0.8627 - precision: 0.8641 - recall: 0.8605 - val_loss: 19.8257 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/19\n",
      "122/122 [==============================] - 19s 153ms/step - loss: 0.3026 - accuracy: 0.9045 - precision: 0.9074 - recall: 0.9008 - val_loss: 0.3015 - val_accuracy: 0.9194 - val_precision: 0.8638 - val_recall: 0.9959\n",
      "Epoch 4/19\n",
      "122/122 [==============================] - 18s 148ms/step - loss: 0.1777 - accuracy: 0.9685 - precision: 0.9632 - recall: 0.9742 - val_loss: 0.3569 - val_accuracy: 0.9194 - val_precision: 0.8612 - val_recall: 1.0000\n",
      "Epoch 5/19\n",
      "122/122 [==============================] - 18s 148ms/step - loss: 0.1915 - accuracy: 0.9665 - precision: 0.9659 - recall: 0.9669 - val_loss: 0.1984 - val_accuracy: 0.9525 - val_precision: 0.9132 - val_recall: 1.0000\n",
      "Epoch 6/19\n",
      "122/122 [==============================] - 19s 154ms/step - loss: 0.1349 - accuracy: 0.9788 - precision: 0.9725 - recall: 0.9855 - val_loss: 0.1451 - val_accuracy: 0.9731 - val_precision: 0.9490 - val_recall: 1.0000\n",
      "Epoch 7/19\n",
      "122/122 [==============================] - 19s 154ms/step - loss: 0.1182 - accuracy: 0.9830 - precision: 0.9815 - recall: 0.9845 - val_loss: 0.2733 - val_accuracy: 0.9194 - val_precision: 0.8612 - val_recall: 1.0000\n",
      "Epoch 8/19\n",
      " 17/122 [===>..........................] - ETA: 14s - loss: 0.1723 - accuracy: 0.9706 - precision: 0.9621 - recall: 0.9769"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "search_result = gp_minimize(func=fitness,\n",
    "                            dimensions=dimensions,\n",
    "                            acq_func='EI', # Expected Improvement.\n",
    "                            n_calls=50,\n",
    "                            x0=default_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "chO3WaWc86SR"
   },
   "outputs": [],
   "source": [
    "load_saved_model = ('model/new_model2.h5')\n",
    "live_model = tf.keras.models.load_model(str(load_saved_model), \n",
    "                                         custom_objects = {'KerasLayer':hub.KerasLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eGRC0ImiKcV8",
    "outputId": "0f8a05e1-e82f-409e-dfab-baf9d5f308c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 50s 114ms/step - loss: 0.3841 - accuracy: 0.9392 - precision: 0.9634 - recall: 0.9650\n",
      "Final loss: 0.38\n",
      "Final accuracy: 93.92%\n",
      "Precision: 96.34%\n",
      "Recall: 96.50%\n",
      "F1-score: 96.42%\n"
     ]
    }
   ],
   "source": [
    "final_loss, final_accuracy, precision, recall = live_model.evaluate(valid_generator, steps = val_steps_per_epoch)\n",
    "print(\"Final loss: {:.2f}\".format(final_loss))\n",
    "print(\"Final accuracy: {:.2f}%\".format(final_accuracy * 100))\n",
    "print(\"Precision: {:.2f}%\".format(precision * 100))\n",
    "print(\"Recall: {:.2f}%\".format(recall* 100))\n",
    "print(\"F1-score: {:.2f}%\".format((2*(precision*recall)/(precision+recall))* 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FaceM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
